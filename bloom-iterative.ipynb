{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed021a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/rick/transformers/src')\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "trulens_path = (Path(os.getcwd()).parent.parent / \"trulens\")\n",
    "\n",
    "sys.path.insert(0, str(trulens_path))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c4603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BloomForCausalLM\n",
    "from transformers import BloomTokenizerFast\n",
    "import torch\n",
    "\n",
    "\n",
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-1b1\")\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom-1b1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a121650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\"\n",
    "model.to(device)\n",
    "tok=tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63890bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Union, Optional\n",
    "from truera.nlp.general.aiq.nlp_coloring import attributions_to_rgb\n",
    "from truera.nlp.general.aiq.nlp_coloring import generate_rgb_str\n",
    "from truera.nlp.general.aiq.nlp_coloring import MAX_INTENSITY\n",
    "from truera.nlp.general.aiq.nlp_coloring import rgb_str\n",
    "from IPython.display import HTML\n",
    "# copied from truera\n",
    "def _influence_examples(\n",
    "        tokens_list: Iterable[Iterable[str]],\n",
    "        attributions_list: Iterable[Iterable[float]],\n",
    "        *,\n",
    "        qoi_class: Union[int, str] = 0,\n",
    "        underline_list: Optional[Union[Iterable[Iterable[int]],\n",
    "                                       Iterable[int]]] = None,\n",
    "        prepends: Union[Iterable[str], str] = ''\n",
    "    ) -> HTML:\n",
    "        \"\"\"\n",
    "        plot the tokens & their attributions for list of token and attributions one by one\n",
    "        underline_list specify the token index to underline (used for plotting influence of a sentence\n",
    "        containing a specific token)\n",
    "        \"\"\"\n",
    "        if len(attributions_list) == 0:\n",
    "            return\n",
    "        norm_factor = np.max(\n",
    "            [\n",
    "                np.max(np.abs(attributions))\n",
    "                for attributions in attributions_list\n",
    "            ]\n",
    "        )\n",
    "        # Display legend\n",
    "        neg_infl_color = rgb_str(256, 256 - MAX_INTENSITY, 256 - MAX_INTENSITY)\n",
    "        neutral_color = rgb_str(256, 256, 256)\n",
    "        pos_infl_color = rgb_str(256 - MAX_INTENSITY, 256, 256 - MAX_INTENSITY)\n",
    "        if isinstance(qoi_class, int):\n",
    "            qoi_class = f\"Class: {qoi_class}\"\n",
    "        qoi_class = qoi_class.replace('_', ' ')\n",
    "        qoi_class = qoi_class.title()\n",
    "        html_str = [\n",
    "            f'''\n",
    "            <div style=\"margin:auto; width:50%; height:20px; display:flex; align-items:center;justify-content: space-between; background-image:linear-gradient(to right, {neg_infl_color}, {neutral_color}, {pos_infl_color});\">\n",
    "                <strong style=margin-left:4px>Negative Influence</strong>\n",
    "                <strong style=text-align:center>{qoi_class}</strong>\n",
    "                <strong style=margin-right:4px>Postive Influence</strong>\n",
    "            </div>\n",
    "            '''\n",
    "        ]\n",
    "\n",
    "        # Plot examples\n",
    "        if isinstance(prepends, str):\n",
    "            prepends = [prepends for _ in range(len(tokens_list))]\n",
    "        for si, (attributions, tokens, prepend) in enumerate(\n",
    "            zip(attributions_list, tokens_list, prepends)\n",
    "        ):\n",
    "            underline_idxs = [\n",
    "                underline_list[si]\n",
    "            ] if underline_list is not None else None\n",
    "            if isinstance(underline_idxs, int):\n",
    "                underline_idxs = [underline_idxs]\n",
    "            line_html = generate_rgb_str(\n",
    "                tokens,\n",
    "                attributions,\n",
    "                underline_idxs,\n",
    "                norm_factor=norm_factor,\n",
    "                max_intensity=MAX_INTENSITY\n",
    "            )\n",
    "            html = f'<p style=padding-bottom:2px><h4 style=margin:0;>{prepend}</h4> {line_html}'\n",
    "            html_str.append(html)\n",
    "\n",
    "        return HTML(\"\\n\".join(html_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c048f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.nn.models import get_model_wrapper\n",
    "from trulens.nn.distributions import PointDoi\n",
    "from trulens.nn.quantities import LambdaQoI\n",
    "from trulens.nn.attribution import IntegratedGradients, Saliency\n",
    "from trulens.nn.attribution import Cut, OutputCut,InputCut\n",
    "from trulens.utils.typing import ModelInputs\n",
    "import numpy as np\n",
    "def explain(inputs, model_inputs, reply_ids, chosen_token):\n",
    "    #chosen_token = 298\n",
    "    wrapper = get_model_wrapper(model)\n",
    "    qoi = LambdaQoI(lambda out: out[-1][-1][chosen_token])\n",
    "    infl = IntegratedGradients(\n",
    "            model=wrapper,\n",
    "            doi_cut=Cut('transformer_word_embeddings'),\n",
    "            qoi_cut=OutputCut(accessor=lambda o: o['logits']),\n",
    "            qoi=qoi,\n",
    "            resolution=128,\n",
    "            rebatch_size=4)\n",
    "    infl = infl.attributions(**model_inputs)\n",
    "    influence_sums = np.sum(infl.attributions[0][0][0],axis=-1)\n",
    "\n",
    "    input_tokens = tokenizer.batch_decode(inputs['input_ids'][0])\n",
    "    display(_influence_examples([input_tokens], [influence_sums], prepends=f\"next token:{tokenizer.decode(chosen_token)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4233b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def explain_utterance(utterance, reply_ids):\n",
    "    #for i in range(len(reply_ids)-1):\n",
    "    #    next_token = i+1\n",
    "    current_utterance = utterance\n",
    "    inputs = tokenizer([utterance], return_tensors=\"pt\").to(device)\n",
    "    for next_token_in_reply in range(len(inputs['input_ids'][0]), len(reply_ids[0])):\n",
    "        chosen_token = int(reply_ids[0][next_token_in_reply])\n",
    "        explain(inputs=inputs, model_inputs=inputs, reply_ids=reply_ids, chosen_token=chosen_token)\n",
    "        current_utterance = current_utterance + tokenizer.decode(chosen_token)\n",
    "        inputs = tokenizer([current_utterance], return_tensors=\"pt\").to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c1b0a",
   "metadata": {},
   "source": [
    "# Model Context\n",
    "Bloom is a document completion model that iteratively predicts the next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "UTTERANCE = \"Complete the names of these NBA players: Michael\"\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\").to(device)\n",
    "reply_ids = model.generate(**inputs,max_length=50, \n",
    "                       no_repeat_ngram_size=2,\n",
    "                       early_stopping=True)\n",
    "print(tokenizer.batch_decode(reply_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270cd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "UTTERANCE = \"Complete the names of these NBA players: Michael Jordan, Kobe\"\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\").to(device)\n",
    "reply_ids = model.generate(**inputs,max_length=50,\n",
    "                       no_repeat_ngram_size=2,\n",
    "                       early_stopping=True)\n",
    "print(tokenizer.batch_decode(reply_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bc258",
   "metadata": {},
   "outputs": [],
   "source": [
    "UTTERANCE = \"Complete the names of these NBA players: Michael Jordan, Kobe Bryant. What about soccer players?\"\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\").to(device)\n",
    "reply_ids = model.generate(**inputs,max_length=100,\n",
    "                       no_repeat_ngram_size=2,\n",
    "                       early_stopping=True)\n",
    "print(tokenizer.batch_decode(reply_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b78f83",
   "metadata": {},
   "source": [
    "# Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff1559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "UTTERANCE = \"Complete the names of these NBA players: Michael\"\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\").to(device)\n",
    "reply_ids = model.generate(**inputs,max_length=200, \n",
    "                       num_beams=2, \n",
    "                       no_repeat_ngram_size=2,\n",
    "                       early_stopping=True)\n",
    "print([f\"{tok_id}: {tokenizer.decode(tok_id)}\" for tok_id in reply_ids[0]])\n",
    "print(tokenizer.batch_decode(reply_ids))\n",
    "#print(reply_ids)\n",
    "explain_utterance(UTTERANCE, reply_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7045c04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_local_nov2022",
   "language": "python",
   "name": "nlp_local_nov2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
