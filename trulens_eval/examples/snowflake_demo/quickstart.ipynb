{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowflake Production-ready RAG Quickstart\n",
    "\n",
    "In this quickstart, we'll show how to build a RAG with the full snowflake stack including Cortex LLM Functions, Cortex Search, and TruLens observability.\n",
    "\n",
    "In addition, we'll show how to run TruLens feedback functions with Cortex as the backend, and how to log TruLens traces and evaluation metrics to a Snowflake table.\n",
    "\n",
    "Last, we'll show how to use TruLens guardrails for filtering retrieved context and reducing hallucination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll install the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install snowflake-snowpark-python\n",
    "# pip install notebook\n",
    "# pip install snowflake-ml-python\n",
    "# pip install trulens-eval\n",
    "# pip install snowflake-sqlalchemy\n",
    "# pip install llama-index\n",
    "# pip install llama-index-readers-github\n",
    "# pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load our credentials and set our Snowflake connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# import necessary packages\n",
    "from snowflake.snowpark.session import Session\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "connection_details = {\n",
    "    'account':  os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    'user': os.environ[\"SNOWFLAKE_USER\"],\n",
    "    'password': os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "    'role': os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "    'database': os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    'schema': os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "    'warehouse': os.environ[\"SNOWFLAKE_WAREHOUSE\"]\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(connection_details).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cortex Complete\n",
    "\n",
    "With the session set, we have what need to call a Snowflake Cortex LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complete() is experimental since 1.0.12. Do not use it in production. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Snowflakes get their unique patterns through a complex process that involves both physics and chemistry. It all starts with a tiny particle in the atmosphere, like a dust or pollen grain, which serves as a nucleus for the snowflake to form around.\n",
      "\n",
      "As this particle cools, water vapor in the air begins to condense and freeze onto it, forming an ice crystal. The shape of this initial crystal is determined by the arrangement of water molecules, which naturally form a hexagonal structure due to the hydrogen bonds between them.\n",
      "\n",
      "As the ice crystal falls through the atmosphere, it encounters different temperatures and levels of humidity. These varying conditions cause the crystal to grow in a unique way, with intricate branches and patterns forming as more water molecules attach to it.\n",
      "\n",
      "The six-sided symmetry of snowflakes comes from the hexagonal structure of water molecules. However, the specific pattern of each snowflake is influenced by the exact path it takes through the atmosphere and the conditions it experiences along the way. This is why no two snowflakes are exactly alike.\n",
      "\n",
      "In essence, the unique patterns of snowflakes are a result of the interplay between the inherent structure of water molecules and the variable conditions in the atmosphere.\n"
     ]
    }
   ],
   "source": [
    "from snowflake.cortex import Complete\n",
    "\n",
    "text = \"\"\"\n",
    "    The Snowflake company was co-founded by Thierry Cruanes, Marcin Zukowski,\n",
    "    and Benoit Dageville in 2012 and is headquartered in Bozeman, Montana.\n",
    "\"\"\"\n",
    "\n",
    "print(Complete(\"mistral-large\", \"how do snowflakes get their unique patterns?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cortex Search\n",
    "\n",
    "Next, we'll turn to the retrieval component of our RAG and set up Cortex Search.\n",
    "\n",
    "This requires three steps:\n",
    "\n",
    "1. Read and preprocess unstructured documents.\n",
    "2. Embed the cleaned documents with Arctic Embed.\n",
    "3. Call the Cortex search service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess unstructured documents\n",
    "\n",
    "For this example, we want to load Cortex Search with documentation from Github about a popular open-source library, Streamlit. To do so, we'll use a GitHub data loader available from LlamaHub.\n",
    "\n",
    "Here we'll also expend some effort to clean up the text so we can get better search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from llama_index.readers.github import GithubRepositoryReader, GithubClient\n",
    "\n",
    "github_token = os.environ[\"GITHUB_TOKEN\"]\n",
    "client = github_client = GithubClient(github_token=github_token, verbose=False)\n",
    "\n",
    "reader = GithubRepositoryReader(\n",
    "    github_client=github_client,\n",
    "    owner=\"streamlit\",\n",
    "    repo=\"docs\",\n",
    "    use_parser=False,\n",
    "    verbose=True,\n",
    "    filter_directories=(\n",
    "        [\"content\"],\n",
    "        GithubRepositoryReader.FilterType.INCLUDE,\n",
    "    ),\n",
    "    filter_file_extensions=(\n",
    "        [\".md\"],\n",
    "        GithubRepositoryReader.FilterType.INCLUDE,\n",
    "    )\n",
    ")\n",
    "\n",
    "documents = reader.load_data(branch=\"main\")\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_up_text(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove unwanted characters and patterns in text input.\n",
    "\n",
    "    :param content: Text input.\n",
    "    \n",
    "    :return: Cleaned version of original text input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix hyphenated words broken by newline\n",
    "    content = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', content)\n",
    "\n",
    "    unwanted_patterns = ['---\\nvisible: false','---', '#','slug:']\n",
    "    for pattern in unwanted_patterns:\n",
    "        content = re.sub(pattern, \"\", content)\n",
    "\n",
    "    # Remove all slugs starting with a \\ and stopping at the first space\n",
    "    content = re.sub(r'\\\\slug: [^\\s]*', '', content)\n",
    "\n",
    "    # normalize whitespace\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    return content\n",
    "\n",
    "cleaned_documents = []\n",
    "\n",
    "for d in documents:\n",
    "    cleaned_text = clean_up_text(d.text)\n",
    "    d.text = cleaned_text\n",
    "    cleaned_documents.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed the preprocessed documents\n",
    "\n",
    "We'll use Snowflake's Arctic Embed model available from HuggingFace to embed the documents. We'll also use Llama-Index's `SemanticSplitterNodeParser` for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\"Snowflake/snowflake-arctic-embed-m\")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1, breakpoint_percentile_threshold=85, embed_model=embed_model\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the embed model and splitter, we can execute them in an ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "cortex_search_pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        splitter,\n",
    "    ],\n",
    ")\n",
    "\n",
    "results = cortex_search_pipeline.run(show_progress=True, documents=cleaned_documents)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Roughly the proportion of chunks that are bigger than 512 tokens (approx 385 English words): {np.mean([len(curr.text.split()) > 385 for curr in res])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data to Cortex Search\n",
    "\n",
    "Now that we've embedded our documents, we're ready to load them to Cortex Search.\n",
    "\n",
    "Here we can use the same connection details as we set up for Cortex Complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import snowflake.connector\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=connection_details[\"user\"],\n",
    "    password=connection_details[\"password\"],\n",
    "    account=connection_details[\"account\"],\n",
    "    warehouse=connection_details[\"warehouse\"],\n",
    "    database=connection_details[\"database\"],\n",
    "    schema=connection_details[\"schema\"]\n",
    ")\n",
    "\n",
    "conn.cursor().execute(\"CREATE OR REPLACE TABLE streamlit_docs(doc_text VARCHAR)\")\n",
    "for curr in tqdm(result):\n",
    "    conn.cursor().execute(\"INSERT INTO streamlit_docs VALUES (%s)\", curr.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Cortex Search Service\n",
    "\n",
    "Here we'll create a CortexSearchRetreiver class to connect to our cortex search service and add the `retrieve` method that we can leverage for calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.core import Root\n",
    "\n",
    "class CortexSearchRetriever:\n",
    "\n",
    "    def __init__(self, session = session, limit_to_retrieve: int = 4):\n",
    "        self.session = session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "    \n",
    "    def retrieve(self, query: str):\n",
    "        root = Root(self.session)\n",
    "        cortex_search_service = root.databases[\n",
    "                os.environ[\"SNOWFLAKE_DATABASE\"]].schemas[\n",
    "                    os.environ[\"SNOWFLAKE_SCHEMA\"]].cortex_search_services[\n",
    "                        os.environ[\"SNOWFLAKE_CORTEX_SEARCH_SERVICE\"]]\n",
    "        resp = cortex_search_service.search(\n",
    "                query=query,\n",
    "                columns=[\"doc_text\"],\n",
    "                limit=self._limit_to_retrieve,\n",
    "            )\n",
    "        if resp.results:\n",
    "            return [curr[\"doc_text\"] for curr in resp.results]\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = CortexSearchRetriever(session=session, limit_to_retrieve=4)\n",
    "\n",
    "retrieved_context = retriever.retrieve(query=\"How do I launch a streamlit app?\")\n",
    "\n",
    "len(retrieved_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a RAG with built-in observability\n",
    "\n",
    "Now that we've set up the components we need from Snowflake Cortex, we can build our RAG.\n",
    "\n",
    "We'll do this by creating a custom python class with each the methods we need. We'll also add TruLens instrumentation with the `@instrument` decorator to our app.\n",
    "\n",
    "The first thing we need to do however, is to set the database connection where we'll log the traces and evaluation results from our application. This way we have a stored record that we can use to understand the app's performance. This is done when initializing `Tru`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "\n",
    "db_url = \"snowflake://{user}:{password}@{account}/{dbname}/{schema}?warehouse={warehouse}&role={role}\".format(\n",
    "    user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "    account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    password=os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "    dbname=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "    schema=os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "    warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    role=os.environ[\"SNOWFLAKE_ROLE\"],\n",
    ")\n",
    "\n",
    "tru = Tru(database_url=db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct the RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "class RAG_from_scratch:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(session=session, limit_to_retrieve=4)\n",
    "    @instrument\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = self.retriever.retrieve(query)\n",
    "        return results\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = Complete(\"mistral-large\",query)\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query)\n",
    "        completion = self.generate_completion(query, context_str)\n",
    "        return completion\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.retrieve_context.rets[:].collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve_context.rets[:] .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback.provider.cortex import Cortex\n",
    "from trulens_eval.feedback import Feedback\n",
    "from trulens_eval import Select\n",
    "import numpy as np\n",
    "\n",
    "provider = Cortex(\"mistral-large\")\n",
    "\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "    provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve_context.rets[:].collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "    provider.context_relevance,\n",
    "    name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve_context.rets[:])\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "f_answer_relevance = (\n",
    "    Feedback(\n",
    "    provider.relevance,\n",
    "    name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "feedbacks = [f_context_relevance,\n",
    "            f_answer_relevance,\n",
    "            f_groundedness,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'RAG v1',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"How do I launch a streamlit app?\",\n",
    "    \"How can I capture the state of my session in streamlit?\",\n",
    "    \"How do I install streamlit?\",\n",
    "    \"How do I change the background color of a streamlit app?\",\n",
    "    \"What's the advantage of using a streamlit form?\",\n",
    "    \"What are some ways I should use checkboxes?\",\n",
    "    \"How can I conserve space and hide away content?\",\n",
    "    \"Can you recommend some resources for learning Streamlit?\",\n",
    "    \"What are some common use cases for Streamlit?\",\n",
    "    \"How can I deploy a streamlit app on the cloud?\",\n",
    "    \"How do I add a logo to streamlit?\",\n",
    "    \"What is the best way to deploy a Streamlit app?\",\n",
    "    \"How should I use a streamlit toggle?\",\n",
    "    \"How do I add new pages to my streamlit app?\",\n",
    "    \"How do I write a dataframe to display in my dashboard?\",\n",
    "    \"Can I plot a map in streamlit? If so, how?\",\n",
    "    \"How do vector stores enable efficient similarity search?\",\n",
    "    \"How do I prevent my child from using the internet?\",\n",
    "    \"What should I pack for a camping trip this weekend?\",\n",
    "    \"How do I defend myself against bear attacks?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        rag.query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   Network URL: http://192.168.4.206:1235\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.run_dashboard(port=1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Answer Relevance  Context Relevance  Groundedness  latency  total_cost\n",
       "app_id                                                                        \n",
       "RAG v1               1.0               0.75      0.815385      6.0         0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I launch a streamlit dashboard?</td>\n",
       "      <td>Your environment's name will appear in parenth...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I launch a streamlit dashboard?</td>\n",
       "      <td>![Watch your app launch](/images/streamlit-com...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I launch a streamlit dashboard?</td>\n",
       "      <td>The first step is to create a new Python scrip...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I launch a streamlit dashboard?</td>\n",
       "      <td>title: Basic concepts of Streamlit /get-start...</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question  \\\n",
       "0  How do I launch a streamlit dashboard?   \n",
       "1  How do I launch a streamlit dashboard?   \n",
       "2  How do I launch a streamlit dashboard?   \n",
       "3  How do I launch a streamlit dashboard?   \n",
       "\n",
       "                                             context  ret  \n",
       "0  Your environment's name will appear in parenth...  0.8  \n",
       "1  ![Watch your app launch](/images/streamlit-com...  0.4  \n",
       "2  The first step is to create a new Python scrip...  0.9  \n",
       "3   title: Basic concepts of Streamlit /get-start...  0.9  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_record = recording.records[-1]\n",
    "\n",
    "from trulens_eval.utils.display import get_feedback_result\n",
    "get_feedback_result(last_record, 'Context Relevance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Guardrails\n",
    "\n",
    "In addition to making informed iteration, we can also directly use feedback results as guardrails at inference time. In particular, here we show how to use the context relevance score as a guardrail to filter out irrelevant context before it gets passed to the LLM. This both reduces hallucination and improves efficiency.\n",
    "\n",
    "To do so, we'll rebuild our RAG using the @context-filter decorator on the method we want to filter, and pass in the feedback function and threshold to use for guardrailing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve.rets .\n"
     ]
    }
   ],
   "source": [
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    ")\n",
    "\n",
    "from trulens_eval.guardrails.base import context_filter\n",
    "\n",
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = (\n",
    "    Feedback(provider.context_relevance, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets)\n",
    ")\n",
    "\n",
    "from trulens_eval.guardrails.base import context_filter\n",
    "\n",
    "class filtered_RAG_from_scratch:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(session=session, limit_to_retrieve=4)\n",
    "    @instrument\n",
    "    @context_filter(f_context_relevance_score, 0.75, keyword_for_prompt=\"query\")\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = self.retriever.retrieve(query)\n",
    "        return results\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        completion = Complete(\"mistral-large\",query)\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query=query)\n",
    "        completion = self.generate_completion(query=query, context_str=context_str)\n",
    "        return completion\n",
    "\n",
    "filtered_rag = filtered_RAG_from_scratch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "filtered_tru_rag = TruCustomApp(filtered_rag,\n",
    "    app_id = 'RAG v2',\n",
    "    feedbacks = [f_groundedness, f_answer_relevance, f_context_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jreini/Desktop/development/trulens/trulens_eval/trulens_eval/feedback/feedback.py:915: UserWarning: Feedback function Context Relevance with aggregation <function mean at 0x1068fafc0> had no inputs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with filtered_tru_rag as recording:\n",
    "    for prompt in prompts:\n",
    "        filtered_rag.query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG v2</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.571732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.285714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG v1</th>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.491251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.285714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Context Relevance  Groundedness  Answer Relevance    latency  \\\n",
       "app_id                                                                 \n",
       "RAG v2           0.854167      0.571732               1.0  23.285714   \n",
       "RAG v1           0.478571      0.491251               1.0  23.285714   \n",
       "\n",
       "        total_cost  \n",
       "app_id              \n",
       "RAG v2         0.0  \n",
       "RAG v1         0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowday",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
