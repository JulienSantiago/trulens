{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Assitants API\n",
    "\n",
    "The [Assistants API](https://platform.openai.com/docs/assistants/overview) allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling.\n",
    "\n",
    "TruLens can be easily integrated with the assistants API to provide the same observability tooling you are used to when building with other frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the assistant\n",
    "\n",
    "Let's create a new assistant that answers questions about the famous *Paul Graham Essay*.\n",
    "\n",
    "The easiest way to get it is to download it via this link and save it in a folder called data. You can do so with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-01 17:35:59--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‚Äòdata/paul_graham_essay.txt.14‚Äô\n",
      "\n",
      "paul_graham_essay.t 100%[===================>]  73.28K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-04-01 17:35:59 (2.20 MB/s) - ‚Äòdata/paul_graham_essay.txt.14‚Äô saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶ë Tru initialized with db url sqlite:///default.sqlite .\n",
      "üõë Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# upload the file\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"data/paul_graham_essay.txt\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "# create the assistant with access to a retrieval tool\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Paul Graham Essay Assistant\",\n",
    "  instructions=\"You are an assistant that answers questions about Paul Graham.\",\n",
    "  tools=[{\"type\": \"retrieval\"}],\n",
    "  model=\"gpt-4-turbo-preview\",\n",
    "  file_ids=[file.id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.beta.assistant.Assistant"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.resources.beta.assistants.assistants import Assistants\n",
    "from openai.resources.beta.assistants.files import Files\n",
    "from openai.resources.beta.threads.threads import Threads\n",
    "from openai.resources.beta.threads.messages.messages import Messages\n",
    "from openai.resources.beta.threads.runs.runs import Runs\n",
    "\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "instrument.method(Assistants, \"create\")\n",
    "instrument.method(Assistants, \"retrieve\")\n",
    "instrument.method(Threads, \"create\")\n",
    "instrument.method(Threads, \"retrieve\")\n",
    "instrument.method(Files, \"create\")\n",
    "instrument.method(Files, \"retrieve\")\n",
    "instrument.method(Messages, \"create\")\n",
    "instrument.method(Messages, \"retrieve\")\n",
    "instrument.method(Runs, \"create\")\n",
    "instrument.method(Runs, \"retrieve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtru_custom_app\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruCustomApp\n\u001b[0;32m----> 2\u001b[0m tru_recorder \u001b[38;5;241m=\u001b[39m TruCustomApp(thread, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPG Essay Assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/trulens_dev_empty/lib/python3.11/site-packages/trulens_eval/tru_custom_app.py:386\u001b[0m, in \u001b[0;36mTruCustomApp.__init__\u001b[0;34m(self, app, methods_to_instrument, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# The rest of this code instruments methods explicitly passed to\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# constructor as needing instrumentation and checks that methods\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# decorated with @instrument or passed explicitly belong to some\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# component as per serialized version of this app. If they are not,\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# placeholders are made in `app_extra_json` so that subsequent\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# serialization looks like the components exist.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dump()\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m, path \u001b[38;5;129;01min\u001b[39;00m methods_to_instrument\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    387\u001b[0m     method_name \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    389\u001b[0m     full_path \u001b[38;5;241m=\u001b[39m Lens()\u001b[38;5;241m.\u001b[39mapp \u001b[38;5;241m+\u001b[39m path\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from trulens_eval.tru_custom_app import TruCustomApp\n",
    "tru_recorder = TruCustomApp(thread, \"PG Essay Assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how did pg grow up?\"\n",
    "message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=question\n",
    "    )\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        instructions=\"Please answer any questions about Paul Graham.\"\n",
    "    )\n",
    "\n",
    "# results are asynchronous, need to wait until the run is completed\n",
    "import time\n",
    "while run.status in ['queued', 'in_progress', 'cancelling']:\n",
    "    time.sleep(1)  # Wait for 1 second\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    "    )\n",
    "\n",
    "if run.status == 'completed': \n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id\n",
    "        )\n",
    "    response = messages.data[0].content[0].text.value  # Assuming the intention is to use or print this variable elsewhere\n",
    "else:\n",
    "    response = run.status  # Assuming the intention is to use or print this variable elsewhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paul Graham grew up with a keen interest in both writing and programming, which were his main activities outside of school before college. His initial endeavor into programming involved writing programs on an IBM 1401, utilized by his school district for what was then referred to as \"data processing\"„Äê7‚Ä†source„Äë.\\n\\nLater in his life, after college and during his time in graduate school and beyond, Graham explored the intersection of art and technology. At a certain point, he even considered becoming an artist and began taking art classes at Harvard. This period of exploration included planning to become an artist while also being deeply engaged in Lisp programming and working on \"On Lisp.\" This multifaceted period of his life illustrated his eclectic interests and talents, spanning from computer science to the arts„Äê9‚Ä†source„Äë.\\n\\nGraham\\'s post-academic career involved a job at Interleaf, a company that had added a scripting language inspired by Emacs, making the scripting language a dialect of Lisp. This was one of the closest experiences Graham had to a \"normal job,\" which he acknowledges wasn\\'t an ideal fit for him due to his self-described irresponsibility and discomfort with the conventional working hours of the programming job at the time„Äê15‚Ä†source„Äë.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [latency, total_cost]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f65064a9f204d53a41c7ba15fcfa337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.1.157:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-prospector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
