{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating on LLM Apps with TruLens\n",
    "\n",
    "1. Start with basic RAG.\n",
    "2. Show failures of RAG Triad.\n",
    "3. Address failures with context filtering, advanced RAG (e.g., sentence windows, auto-retrieval)\n",
    "4. Improve RAG with agents\n",
    "5. Showcase experiment tracking to choose best app configuration. \n",
    "6. Weave in different types of evals into narrative\n",
    "7. Weave in user/customer stories into narrative\n",
    "\n",
    "\n",
    "## Notes:\n",
    "\n",
    "Use Insurance policy as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API keys. If you already have them in your var env., you can skip these steps.\n",
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with basic RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./Insurance_Handbook_20103.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "from llama_index import ServiceContext, VectorStoreIndex, StorageContext\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# initialize llm\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "# knowledge store\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "# service context for index\n",
    "service_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# create index\n",
    "index = VectorStoreIndex.from_documents([document], service_context=service_context)\n",
    "\n",
    "from llama_index import Prompt\n",
    "\n",
    "system_prompt = Prompt(\"SYSTEM PROMPT: You are an insurance assistant who is charged with answering questions completely.\\n\"\n",
    "    \"We have provided context information below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given this system prompt and context, please answer the question: {query_str}\\n\")\n",
    "\n",
    "# basic rag query engine\n",
    "rag_basic = index.as_query_engine(text_qa_template = system_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some questions for evaluation\n",
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 8 rows.\n",
      "✅ In Answer Relevance, input prompt will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input prompt will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input response will be set to *.__record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to *.__record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input statement will be set to *.__record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from trulens_eval import Tru, Feedback, TruLlama, OpenAI as fOpenAI\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "# start fresh\n",
    "tru.reset_database()\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "openai = fOpenAI()\n",
    "\n",
    "qa_relevance = (\n",
    "    Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")\n",
    "\n",
    "qs_relevance = (\n",
    "    Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(TruLlama.select_source_nodes().node.text)\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=openai)\n",
    "\n",
    "groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "        .on(TruLlama.select_source_nodes().node.text)\n",
    "        .on_output()\n",
    "        .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "feedbacks = [qa_relevance, qs_relevance, groundedness]\n",
    "\n",
    "from trulens_eval import FeedbackMode\n",
    "\n",
    "tru_recorder_rag_basic = TruLlama(\n",
    "        rag_basic,\n",
    "        app_id='Basic RAG',\n",
    "        feedbacks=feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa114ab9637480aae36e0bb04ef077f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.23:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 0.0}\n",
      "Groundedness scores: {'statement_0': 0.8}\n",
      "Groundedness scores: {'statement_0': 0.8}\n",
      "Groundedness scores: {'statement_0': 0.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 0.0}\n",
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0, 'statement_3': 1.0, 'statement_4': 1.0}\n",
      "Groundedness scores: {'statement_0': 0.0, 'statement_1': 0.0, 'statement_2': 0.0, 'statement_3': 0.0, 'statement_4': 0.0}\n",
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 0.7, 'statement_1': 1.0, 'statement_2': 1.0, 'statement_3': 1.0, 'statement_4': 1.0, 'statement_5': 0.0}\n",
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 0.0}\n",
      "Groundedness scores: {'statement_0': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 0.0}\n",
      "Groundedness scores: {'statement_0': 0.0}\n",
      "Groundedness scores: {'statement_0': 0.0}\n",
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0, 'statement_3': 1.0, 'statement_4': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation on 10 sample questions\n",
    "with tru_recorder_rag_basic as recording:\n",
    "    for question in eval_questions:\n",
    "        response = rag_basic.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tru.stop_evaluator()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple RAG often struggles with retrieving not enough information from the insurance manual to properly answer the question. The information needed may be just outside the chunk that is identified and retrieved by our app. Let's try sentence window retrieval to retrieve a wider chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index import load_index_from_storage\n",
    "import os\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=3,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            [document], service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
    ")\n",
    "\n",
    "def get_sentence_window_query_engine(\n",
    "    sentence_index,\n",
    "    similarity_top_k=6,\n",
    "    rerank_top_n=2,\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)\n",
    "\n",
    "tru_recorder_rag_sentencewindow = TruLlama(\n",
    "        sentence_window_engine,\n",
    "        app_id='RAG - Sentence Window',\n",
    "        feedbacks=feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function BaseQueryEngine.query at 0x138000a40>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n",
      "A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x11210f190 is calling an instrumented method <function BaseRetriever.retrieve at 0x1459cfce0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app.retriever based on other object (0x1a3e1bd10) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function CompactAndRefine.get_response at 0x138818680>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.llm_predictor.base.LLMPredictor'> at 0x1a61cfe10 is calling an instrumented method <function LLMPredictor.predict at 0x13908c0e0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer.service_context.llm_predictor based on other object (0x1458d9250) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 0.5, 'statement_1': 0.3, 'statement_2': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 0.0, 'statement_3': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0, 'statement_3': 1.0, 'statement_4': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0, 'statement_3': 1.0, 'statement_4': 0.0, 'statement_5': 0.0}\n",
      "Task queue full. Finishing existing tasks.\n",
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0, 'statement_3': 1.0, 'statement_4': 1.0, 'statement_5': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 0.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1a64d8b50 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a60fb850 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation on 10 sample questions\n",
    "with tru_recorder_rag_sentencewindow as recording:\n",
    "    for question in eval_questions:\n",
    "        response = sentence_window_engine.query(question)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add in more evals: Controversiality, Embedding Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In controversiality, input text will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
      "✅ In cosine_distance, input query will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In cosine_distance, input document will be set to *.__record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "# controversiality\n",
    "f_controversiality = Feedback(openai.controversiality, name = \"Controversiality\").on_output() \n",
    "\n",
    "# embedding distance\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from trulens_eval.feedback import Embeddings\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed_model = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "embed = Embeddings(embed_model=embed_model)\n",
    "f_embed_dist = (\n",
    "    Feedback(embed.cosine_distance, name=\"Context Embedding Distance\")\n",
    "    .on_input()\n",
    "    .on(TruLlama.select_source_nodes().node.text)\n",
    ")\n",
    "\n",
    "expanded_feedbacks = feedbacks + [f_controversiality, f_embed_dist]\n",
    "\n",
    "tru_recorder_rag_sentencewindow = TruLlama(\n",
    "        sentence_window_engine,\n",
    "        app_id='RAG - Sentence Window',\n",
    "        feedbacks=expanded_feedbacks\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice problem with high temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower temperature\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
    ")\n",
    "\n",
    "sentence_window_engine_lowtemp = get_sentence_window_query_engine(sentence_index)\n",
    "\n",
    "tru_recorder_rag_sentencewindow_lowtemp = TruLlama(\n",
    "        sentence_window_engine_lowtemp,\n",
    "        app_id='RAG - Sentence Window - Low Temp',\n",
    "        feedbacks=expanded_feedbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function BaseQueryEngine.query at 0x138000a40>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n",
      "A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x1a6fba190 is calling an instrumented method <function BaseRetriever.retrieve at 0x1459cfce0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app.retriever based on other object (0x1a3e1bd10) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function CompactAndRefine.get_response at 0x138818680>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.llm_predictor.base.LLMPredictor'> at 0x1ac9fdc50 is calling an instrumented method <function LLMPredictor.predict at 0x13908c0e0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer.service_context.llm_predictor based on other object (0x1458d9250) using this function.\n",
      "A new object of type <class 'llama_index.llms.openai.OpenAI'> at 0x1ac9ffd10 is calling an instrumented method <function llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat at 0x137ace8e0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer.service_context.llm based on other object (0x14615a350) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0}\n",
      "Groundedness scores: {'statement_0': 0.5, 'statement_1': 0.3, 'statement_2': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0, 'statement_3': 1.0, 'statement_4': 0.0, 'statement_5': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0, 'statement_3': 1.0, 'statement_4': 1.0, 'statement_5': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 1.0, 'statement_2': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0, 'statement_1': 0.0, 'statement_2': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task queue full. Finishing existing tasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n",
      "A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x1ac9eec10 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x1a3e693a0>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app based on other object (0x1a3e1bd90) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x1a6fba290 is calling an instrumented method <function Refine.get_response at 0x1459ce340>. The path of this call may be incorrect.\n",
      "Guessing path of new object is *.app._response_synthesizer based on other object (0x1a3e11a50) using this function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundedness scores: {'statement_0': 1.0}\n",
      "Groundedness scores: {'statement_0': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation on 10 sample questions\n",
    "with tru_recorder_rag_sentencewindow_lowtemp as recording:\n",
    "    for question in eval_questions:\n",
    "        response = sentence_window_engine_lowtemp.query(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
