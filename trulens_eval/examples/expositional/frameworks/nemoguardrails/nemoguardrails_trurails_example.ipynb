{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring and Evaluating NEMO Guardrails apps\n",
    "\n",
    "TODO: This notebook is in an experimental state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall -y trulens_eval\n",
    "# pip install git+https://github.com/truera/trulens@piotrm/azure_bugfixes#subdirectory=trulens_eval\n",
    "\n",
    "# trulens_eval notebook dev\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "base = Path().cwd()\n",
    "while not (base / \"trulens_eval\").exists():\n",
    "    base = base.parent\n",
    "\n",
    "print(base)\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(base))\n",
    "\n",
    "# TODO: presently we use some features of a modified version of NeMo-Guardrails.\n",
    "# Either point path to it or install from branch.\n",
    "sys.path.append(\"/Volumes/dev_new/NeMo-Guardrails\")\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\",\n",
    "    \"HUGGINGFACE_API_KEY\"\n",
    ")\n",
    "\n",
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "tru.run_dashboard(_dev=base, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rails app setup\n",
    "\n",
    "The files created below define a configuration of a rails app adapted from\n",
    "various examples in the NeMo-Guardrails repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.yaml\n",
    "# Adapted from NeMo-Guardrails/nemoguardrails/examples/bots/abc/config.yml\n",
    "instructions:\n",
    "  - type: general\n",
    "    content: |\n",
    "      Below is a conversation between a user and a bot called the trulens Bot.\n",
    "      The bot is designed to answer questions about the trulens_eval python library.\n",
    "      The bot is knowledgeable about python.\n",
    "      If the bot does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "sample_conversation: |\n",
    "  user \"Hi there. Can you help me with some questions I have about trulens?\"\n",
    "    express greeting and ask for assistance\n",
    "  bot express greeting and confirm and offer assistance\n",
    "    \"Hi there! I'm here to help answer any questions you may have about the trulens. What would you like to know?\"\n",
    "\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-3.5-turbo-instruct\n",
    "\n",
    "#knowledge_base: # no longer works with openai >= 1.0\n",
    "#  embedding_search_provider:\n",
    "#    name: default\n",
    "#    parameters:\n",
    "#      embedding_engine: openai\n",
    "#      embedding_model: text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.co\n",
    "# Adapted from NeMo-Guardrails/tests/test_configs/with_kb_openai_embeddings/config.co\n",
    "define user ask capabilities\n",
    "  \"What can you do?\"\n",
    "  \"What can you help me with?\"\n",
    "  \"tell me what you can do\"\n",
    "  \"tell me about you\"\n",
    "\n",
    "define bot inform capabilities\n",
    "  \"I am an AI bot that helps answer questions about trulens_eval.\"\n",
    "\n",
    "define flow\n",
    "  user ask capabilities\n",
    "  bot inform capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rails app instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\".\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.feedback import RAG_triad\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval.schema import Select\n",
    "from trulens_eval.tru_rails import TruRails\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "\n",
    "context = App.select_context(rails)\n",
    "question = Select.RecordInput\n",
    "answer = Select.RecordOutput\n",
    "\n",
    "triad = RAG_triad(\n",
    "    provider=openai,\n",
    "    question=question, answer=answer, context=context\n",
    ")\n",
    "\n",
    "pprint(triad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TruRails` recorder instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_rails = TruRails(rails, feedbacks=triad.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logged invocation\n",
    "\n",
    "Using `tru_rails` as a context manager means the invocations of the rail app\n",
    "will be logged and feedback will be evaluated on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rails as recorder:\n",
    "    response = await rails.generate_async(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Can I use AzureOpenAI to define a provider?\"\n",
    "}])\n",
    "    \n",
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback retrieval\n",
    "\n",
    "Feedback results can be viewed on the dashboard or retrieved from the record produced by the context mamanger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = recorder.get()\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for fut in as_completed(record.feedback_results):\n",
    "    feedback, result = fut.result()\n",
    "    print(feedback.name, result.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
