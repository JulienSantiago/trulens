{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Companion: Iterating on NeMo Guardrails apps with TruLens\n",
    "\n",
    "This notebook demonstrates how to instrument _NeMo Guardrails_ apps to monitor\n",
    "their invocations and run feedback functions on their final or intermediate\n",
    "results. The reverse integration, of using trulens within rails apps, is shown\n",
    "in the other notebook in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NeMo Guardrails and trulens_eval if not already installed.\n",
    "#! pip install nemoguardrails trulens_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup keys and trulens_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No .env found in /Users/jreini/Desktop/development/trulens/trulens_eval/examples/expositional/frameworks/nemoguardrails or its parents. You may need to specify secret keys in another manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Key OPENAI_API_KEY set from explicit value to `check_or_set_keys`.\n",
      "âœ… Key HUGGINGFACE_API_KEY set from explicit value to `check_or_set_keys`.\n",
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "# This notebook uses openai and huggingface providers which need some keys set.\n",
    "# You can set them here:\n",
    "\n",
    "from trulens_eval.keys import check_or_set_keys\n",
    "check_or_set_keys(\n",
    "    OPENAI_API_KEY=\"sk-...\",\n",
    "    HUGGINGFACE_API_KEY=\"hf_...\"\n",
    ")\n",
    "\n",
    "# Load trulens, reset the database:\n",
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rails app setup\n",
    "\n",
    "The files created below define a configuration of a rails app adapted from\n",
    "various examples in the NeMo-Guardrails repository. There is nothing unusual\n",
    "about the app beyond the knowledge base here being the trulens_eval\n",
    "documentation. This means you should be able to ask the resulting bot questions\n",
    "regarding trulens instead of the fictional company handbook as was the case in\n",
    "the originating example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "# Adapted from NeMo-Guardrails/nemoguardrails/examples/bots/abc/config.yml\n",
    "instructions:\n",
    "  - type: general\n",
    "    content: |\n",
    "      Below is a conversation between a user and a bot called the trulens nemo guardrails Bot.\n",
    "      The bot is designed to answer questions about the trulens_eval and nemo guardrails python library.\n",
    "      The bot is knowledgeable about python.\n",
    "      If the bot does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "input:\n",
    "  flows:\n",
    "    - check blocked terms\n",
    "    - self check input\n",
    "\n",
    "output:\n",
    "  flows:\n",
    "    - check blocked terms\n",
    "    - self check output\n",
    "\n",
    "sample_conversation: |\n",
    "  user \"Hi there. Can you help me with some questions I have about trulens and nemo guardrails?\"\n",
    "    express greeting and ask for assistance\n",
    "  bot express greeting and confirm and offer assistance\n",
    "    \"Hi there! I'm here to help answer any questions you may have about trulens and nemo guardrails. What would you like to know?\"\n",
    "\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-3.5-turbo-instruct\n",
    "\n",
    "user_capabilities:\n",
    "  - \"how can nemo guardrails keep a conversational system on topic, safe and secure?\"\n",
    "  - \"how can trulens be used to evaluate an llm application for groundedness\"\n",
    "  - \"what's the best way to measure the effectiveness of a retrieval system with trulens\"\n",
    "  - \"What can you help me with?\"\n",
    "  - \"tell me what you can do\"\n",
    "  - \"tell me about you\"\n",
    "  - \"how can AI conversational systems improve user experience?\"\n",
    "  - \"what are the best practices for implementing trulens in a project?\"\n",
    "  - \"can you explain how nemo guardrails ensure data privacy?\"\n",
    "  - \"what are the limitations of AI conversational systems?\"\n",
    "\n",
    "bot_capabilities:\n",
    "  - \"I am an AI bot that helps answer questions about trulens_eval, nemo guardrails, and general AI conversational systems. I can provide insights on how to implement these technologies effectively and safely.\"\n",
    "\n",
    "conversation_flow:\n",
    "  - user: ask capabilities\n",
    "  - check blocked terms\n",
    "  - bot: explain usage and capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.co\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.co\n",
    "# Adapted from NeMo-Guardrails/tests/test_configs/with_kb_openai_embeddings/config.co\n",
    "define user ask capabilities\n",
    "  \"how can nemo guardrails be used to do X?\"\n",
    "  \"why is trulens useful for doing Y?\"\n",
    "  \"What can you help me with?\"\n",
    "  \"tell me what you can do\"\n",
    "  \"tell me about you\"\n",
    "  \"how can AI conversational systems improve user experience?\"\n",
    "  \"what are the best practices for implementing trulens in a project?\"\n",
    "  \"can you explain how nemo guardrails ensure data privacy?\"\n",
    "  \"what are the limitations of AI conversational systems?\"\n",
    "\n",
    "define bot inform capabilities\n",
    "  \"I am an AI bot that helps answer questions about trulens_eval, nemo guardrails, and general AI conversational systems. I can provide insights on how to implement these technologies effectively and safely.\"\n",
    "\n",
    "define flow\n",
    "  user ask capabilities\n",
    "  bot explain usage and capabilities\n",
    "\n",
    "define subflow self check output\n",
    "  $allowed = execute self_check_output\n",
    "\n",
    "define subflow self check input\n",
    "  $allowed = execute self_check_input\n",
    "\n",
    "  if not $allowed\n",
    "    bot refuse to respond\n",
    "    stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rails app instantiation\n",
    "\n",
    "The instantiation of the app does not differ from the steps presented in NeMo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6905cab11b7f462d89c2ee25d7206f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\".\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rails.kb is not None, \"Knowledge base not loaded. You might be using the wrong nemo release or branch.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback functions setup\n",
    "\n",
    "Lets consider some feedback functions. We will define two types: a simple\n",
    "language match that checks whether output of the app is in the same language as\n",
    "the input. The second is a set of three for evaluating context retrieval. The\n",
    "setup for these is similar to that for other app types such as langchain except\n",
    "we provide a utility `RAG_triad` to create the three context retrieval functions\n",
    "for you instead of having to create them seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Language Match, input text1 will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Language Match, input text2 will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "FeedbackDefinition(Language Match,\n",
      "\tselectors={'text1': Lens().__record__.main_input, 'text2': Lens().__record__.main_output},\n",
      "\tif_exists=__record__.main_output\n",
      ")\n",
      "{'Answer Relevance': FeedbackDefinition(Answer Relevance,\n",
      "\tselectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output},\n",
      "\tif_exists=__record__.app.kb.search_relevant_chunks.rets[:].body\n",
      "),\n",
      " 'Context Relevance': FeedbackDefinition(Context Relevance,\n",
      "\tselectors={'question': Lens().__record__.main_input, 'context': Lens().__record__.app.kb.search_relevant_chunks.rets[:].body},\n",
      "\tif_exists=__record__.app.kb.search_relevant_chunks.rets[:].body\n",
      "),\n",
      " 'Groundedness': FeedbackDefinition(Groundedness,\n",
      "\tselectors={'source': Lens().__record__.app.kb.search_relevant_chunks.rets[:].body.collect(), 'statement': Lens().__record__.main_output},\n",
      "\tif_exists=__record__.app.kb.search_relevant_chunks.rets[:].body\n",
      ")}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jreini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from trulens_eval import Select\n",
    "from trulens_eval.feedback import Feedback\n",
    "from trulens_eval.feedback.feedback import rag_triad\n",
    "from trulens_eval.feedback.provider import Huggingface\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval.tru_rails import TruRails\n",
    "\n",
    "# Initialize provider classes\n",
    "openai = OpenAI()\n",
    "hugs = Huggingface()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "\n",
    "context = App.select_context(rails)\n",
    "question = Select.RecordInput\n",
    "answer = Select.RecordOutput\n",
    "\n",
    "f_language_match = Feedback(hugs.language_match, if_exists=answer, name = \"Language Match\").on(question).on(answer)\n",
    "\n",
    "fs_triad = rag_triad(\n",
    "    provider=openai,\n",
    "    question=question, answer=answer, context=context\n",
    ")\n",
    "\n",
    "# Overview of the 4 feedback functions defined.\n",
    "pprint(f_language_match)\n",
    "pprint(fs_triad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TruRails` recorder instantiation\n",
    "\n",
    "Tru recorder construction is identical to other app types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_rails = TruRails(\n",
    "    rails,\n",
    "    app_id = \"Rails Application\", # optional\n",
    "    feedbacks=[f_language_match, *fs_triad.values()] # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logged app invocation\n",
    "\n",
    "Using `tru_rails` as a context manager means the invocations of the rail app\n",
    "will be logged and feedback will be evaluated on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [\n",
    "    \"How are feedback functions implemented\",\n",
    "    \"How can NVIDIA Nemo be used to create a safe conversational system?\",\n",
    "    \"Â¿CÃ³mo se puede utilizar NVIDIA Nemo para crear un sistema conversacional seguro?\",\n",
    "    \"Can I use AzureOpenAI to define a trulens feedback provider?\",\n",
    "    \"Answer in spanish, can I use AzureOpenAI to define a trulens feedback provider?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "The trulens_eval library provides built-in functions for collecting and analyzing user feedback. These functions can be customized and extended to fit specific use cases.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc892814cc945878f3634c7b99f10c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545a560b25cd46d99def3e77bbfdd398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Nemo can be used to create a safe conversational system by implementing the trulens_eval library and utilizing the nemo guardrails for sensitive data detection. It can also help with input and output moderation using Llama Guard.\n",
      "NVIDIA Nemo is a deep learning framework for building conversational AI systems. It can be used to create secure systems by implementing guardrails from the trulens_eval library.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee3487838fb4574a480aba85a1542a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, both trulens_eval and nemo guardrails are compatible with python. You can use the AzureOpenAI provider to define a feedback provider for trulens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6678bd5bc3524014a7d43f4e789549b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can use the AzureOpenAI provider to define a trulens feedback provider. This combination is compatible with python, and you can find more details on how to use them together in the documentation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252c9fa71f7444af88998231901159ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_rails as recorder:\n",
    "    for test_prompt in test_set:\n",
    "        res = rails.generate(messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": test_prompt\n",
    "        }])\n",
    "        print(res['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard\n",
    "\n",
    "You should be able to view the above invocation in the dashboard. It can be\n",
    "started with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the app\n",
    "\n",
    "We noticed several issues with the app. The most important one is that the bot\n",
    "does not follow the instructions given in the conversation. It does not respond\n",
    "in the same language as the user, and it does not use the available context to\n",
    "answer the core intent of the question.\n",
    "\n",
    "Here we'll expand our config.yaml to fix the issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "# Adapted from NeMo-Guardrails/nemoguardrails/examples/bots/abc/config.yml\n",
    "instructions:\n",
    "  - type: general\n",
    "    content: |\n",
    "      Below is a conversation between a user and a bot called the trulens nemo guardrails Bot.\n",
    "      The bot is designed to answer questions about the trulens_eval and nemo guardrails python library.\n",
    "      The bot is knowledgeable about python.\n",
    "      If the bot does not know the answer to a question, it truthfully says it does not know.\n",
    "      The bot only responds with information on the technology mentioned in the question\n",
    "      The bot uses all available context to answer the core intent of the question\n",
    "      The bot follows the complete instructions given, including to respond in a particular language\n",
    "      The bot always answering the question in the same language it is asked, unless requested otherwise\n",
    "\n",
    "input:\n",
    "  flows:\n",
    "    - check blocked terms\n",
    "    - self check input\n",
    "\n",
    "output:\n",
    "  flows:\n",
    "    - check blocked terms\n",
    "    - self check output\n",
    "\n",
    "sample_conversation: |\n",
    "  user \"Hi there. Can you help me with some questions I have about trulens and nemo guardrails?\"\n",
    "    express greeting and ask for assistance\n",
    "  bot express greeting and confirm and offer assistance\n",
    "    \"Hi there! I'm here to help answer any questions you may have about trulens and nemo guardrails. What would you like to know?\"\n",
    "\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-3.5-turbo-instruct\n",
    "\n",
    "user_capabilities:\n",
    "  - \"how can nemo guardrails keep a conversational system on topic, safe and secure?\"\n",
    "  - \"how can trulens be used to evaluate an llm application for groundedness\"\n",
    "  - \"what's the best way to measure the effectiveness of a retrieval system with trulens\"\n",
    "  - \"What can you help me with?\"\n",
    "  - \"tell me what you can do\"\n",
    "  - \"tell me about you\"\n",
    "  - \"how can AI conversational systems improve user experience?\"\n",
    "  - \"what are the best practices for implementing trulens in a project?\"\n",
    "  - \"can you explain how nemo guardrails ensure data privacy?\"\n",
    "  - \"what are the limitations of AI conversational systems?\"\n",
    "\n",
    "bot_capabilities:\n",
    "  - \"I am an AI bot that helps answer questions about trulens_eval, nemo guardrails, and general AI conversational systems. I can provide insights on how to implement these technologies effectively and safely.\"\n",
    "\n",
    "conversation_flow:\n",
    "  - user: ask capabilities\n",
    "  - check blocked terms\n",
    "  - bot: explain usage and capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can re-instantiate the rails app and the trulens recorder with a new app_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\".\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_rails = TruRails(\n",
    "    rails,\n",
    "    app_id = \"Rails Application - v2\", # optional\n",
    "    feedbacks=[f_language_match, *fs_triad.values()] # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback functions are implemented by wrapping a supported provider's model, such as a relevance model or sentiment classifier. This allows for flexibility in combining different feedback providers and extending them with custom feedback implementations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12142d36d142477d887d89113b6f878a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90e78d17f7f415fb4f838c5b249dd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Nemo can be used to create a safe conversational system by utilizing the nemo guardrails library. This library provides tools for sensitive data detection and moderation, as well as other safety measures. By implementing these tools, you can ensure that your conversational system is secure and protects sensitive information.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c423777e3d4a85ac86bc653b4b28ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puedo proporcionar informaciÃ³n sobre cÃ³mo utilizar NVIDIA Nemo para crear sistemas conversacionales seguros. Â¿Tiene alguna pregunta especÃ­fica sobre la implementaciÃ³n de esta tecnologÃ­a?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bc847ad3e64f5185f0c22278663887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can use AzureOpenAI to define a trulens feedback provider. It is one of the providers that uses large language models for feedback evaluation. You can also use AzureOpenAI to run feedback functions and defer evaluations to off-peak times. Would you like more information on this?\n",
      "SÃ­, puedes usar el proveedor AzureOpenAI para definir un proveedor de comentarios de trulens. AdemÃ¡s, puedo proporcionar informaciÃ³n sobre cÃ³mo implementar esta tecnologÃ­a de manera efectiva y segura.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ca57201647467083807c5c5a62bfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_rails as recorder:\n",
    "    for test_prompt in test_set:\n",
    "        res = rails.generate(messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": test_prompt\n",
    "        }])\n",
    "        print(res['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking actions based on feedback results\n",
    "\n",
    "An additional way to improve our app is to take guardrails actions based on the feedback results.\n",
    "\n",
    "To do so, we first need to register our feedback functions as Feedback Actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registered feedback function under name Groundedness\n",
      "registered feedback function under name Answer Relevance\n",
      "registered feedback function under name Context Relevance\n",
      "registered feedback function under name Language Match\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.tru_rails import FeedbackActions\n",
    "\n",
    "FeedbackActions.register_feedback_functions(**fs_triad)\n",
    "FeedbackActions.register_feedback_functions(f_language_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to identify the lens shorthands for the feedback functions that will be executed by our rails app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['action.context.last_user_message', 'action.context.bot_message', 'action.context.relevant_chunks_sep']\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.tru_rails import RailsActionSelect\n",
    "\n",
    "question_lens = RailsActionSelect.LastUserMessage\n",
    "answer_lens = RailsActionSelect.BotMessage # not LastBotMessage as the flow is evaluated before LastBotMessage is available\n",
    "contexts_lens = RailsActionSelect.RetrievalContexts\n",
    "\n",
    "# Inspect the values of the shorthands:\n",
    "print(list(map(str, [question_lens, answer_lens, contexts_lens])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can update our configuration files with new flows to execute and check the results of our feedback functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.utils.notebook_utils import writefileinterpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefileinterpolated config.yaml\n",
    "# Adapted from NeMo-Guardrails/nemoguardrails/examples/bots/abc/config.yml\n",
    "instructions:\n",
    "  - type: general\n",
    "    content: |\n",
    "      Below is a conversation between a user and a bot called the trulens nemo guardrails Bot.\n",
    "      The bot is designed to answer questions about the trulens_eval and nemo guardrails python library.\n",
    "      The bot is knowledgeable about python.\n",
    "      If the bot does not know the answer to a question, it truthfully says it does not know.\n",
    "      The bot only responds with information on the technology mentioned in the question\n",
    "      The bot uses all available context to answer the core intent of the question\n",
    "      The bot follows the complete instructions given, including to respond in a particular language\n",
    "      The bot always answering the question in the same language it is asked, unless requested otherwise\n",
    "\n",
    "input:\n",
    "  flows:\n",
    "    - check blocked terms\n",
    "    - self check input\n",
    "\n",
    "output:\n",
    "  flows:\n",
    "    - check language match\n",
    "    # triad defined seperately so hopefully they can be executed in parallel\n",
    "    - check rag triad groundedness\n",
    "    - check rag triad relevance\n",
    "    - check rag triad qs_relevance\n",
    "    - bot: explain usage and capabilities\n",
    "\n",
    "sample_conversation: |\n",
    "  user \"Hi there. Can you help me with some questions I have about trulens and nemo guardrails?\"\n",
    "    express greeting and ask for assistance\n",
    "  bot express greeting and confirm and offer assistance\n",
    "    \"Hi there! I'm here to help answer any questions you may have about trulens and nemo guardrails. What would you like to know?\"\n",
    "\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-3.5-turbo-instruct\n",
    "\n",
    "user_capabilities:\n",
    "  - \"how can nemo guardrails keep a conversational system on topic, safe and secure?\"\n",
    "  - \"how can trulens be used to evaluate an llm application for groundedness\"\n",
    "  - \"what's the best way to measure the effectiveness of a retrieval system with trulens\"\n",
    "  - \"What can you help me with?\"\n",
    "  - \"tell me what you can do\"\n",
    "  - \"tell me about you\"\n",
    "  - \"how can AI conversational systems improve user experience?\"\n",
    "  - \"what are the best practices for implementing trulens in a project?\"\n",
    "  - \"can you explain how nemo guardrails ensure data privacy?\"\n",
    "  - \"what are the limitations of AI conversational systems?\"\n",
    "\n",
    "bot_capabilities:\n",
    "  - \"I am an AI bot that helps answer questions about trulens_eval, nemo guardrails, and general AI conversational systems. I can provide insights on how to implement these technologies effectively and safely.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefileinterpolated config.co\n",
    "# Adapted from NeMo-Guardrails/tests/test_configs/with_kb_openai_embeddings/config.co\n",
    "define user ask capabilities\n",
    "  \"how can nemo guardrails be used to do X?\"\n",
    "  \"why is trulens useful for doing Y?\"\n",
    "  \"What can you help me with?\"\n",
    "  \"tell me what you can do\"\n",
    "  \"tell me about you\"\n",
    "  \"how can AI conversational systems improve user experience?\"\n",
    "  \"what are the best practices for implementing trulens in a project?\"\n",
    "  \"can you explain how nemo guardrails ensure data privacy?\"\n",
    "  \"what are the limitations of AI conversational systems?\"\n",
    "\n",
    "define bot inform language mismatch\n",
    "  \"Sorry, I may not be able to answer in your language.\"\n",
    "\n",
    "define bot inform triad failure\n",
    "  \"I may may have made a mistake interpreting your question or my knowledge base. Please try rephrasing your question.\"\n",
    "\n",
    "define parallel subflow check language match\n",
    "  $langmatch_result = execute feedback(\\\n",
    "    function=\"language_match\",\\\n",
    "    selectors={{\\\n",
    "      \"text1\":\"{question_lens}\",\\\n",
    "      \"text2\":\"{answer_lens}\"\\\n",
    "    }},\\\n",
    "    verbose=True\\\n",
    "  )\n",
    "\n",
    "define parallel subflow check rag triad groundedness\n",
    "  $result = execute feedback(\\\n",
    "    function=\"groundedness_measure_with_cot_reasons\",\\\n",
    "    selectors={{\\\n",
    "      \"statement\":\"{answer_lens}\",\\\n",
    "      \"source\":\"{contexts_lens}\"\\\n",
    "    }},\\\n",
    "    verbose=True\\\n",
    "  )\n",
    "\n",
    "define parallel subflow check rag triad relevance\n",
    "  $result = execute feedback(\\\n",
    "    function=\"relevance\",\\\n",
    "    selectors={{\\\n",
    "      \"prompt\":\"{question_lens}\",\\\n",
    "      \"response\":\"{contexts_lens}\"\\\n",
    "    }},\\\n",
    "    verbose=True\\\n",
    "  )\n",
    "\n",
    "define parallel subflow check rag triad qs_relevance\n",
    "  $result = execute feedback(\\\n",
    "    function=\"qs_relevance\",\\\n",
    "    selectors={{\\\n",
    "      \"question\":\"{question_lens}\",\\\n",
    "      \"statement\":\"{answer_lens}\"\\\n",
    "    }},\\\n",
    "    verbose=True\\\n",
    "  )\n",
    "\n",
    "  if $langmatch_result < 0.8\n",
    "    bot inform language mismatch\n",
    "    stop\n",
    "\n",
    "  if $groundedness_result < 0.7\n",
    "    bot inform triad failure\n",
    "    stop\n",
    "\n",
    "  if $answerrelevance_result < 0.7\n",
    "    bot inform triad failure\n",
    "    stop\n",
    "\n",
    "  if $contextrelevance_result < 0.7\n",
    "    bot inform triad failure\n",
    "    stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconfigure our rails application and TruLens recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\".\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails.register_action(FeedbackActions.feedback_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruRails\n",
    "\n",
    "tru_rails = TruRails(rails,\n",
    "                     app_id = \"Rails Application - v3\", # optional\n",
    "    feedbacks=[f_language_match, *fs_triad.values()] # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback functions are implemented in the trulens_eval and nemo guardrails python library. They provide a programmatic method for generating evaluations on an application run by wrapping a supported provider's model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb462246fea4ba0b25a3284b68c9bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe664b6bed841bf98d44dee5d3a47d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NVIDIA Nemo library can be used to create a safe conversational system by implementing sensitive data detection mechanisms such as Llama Guard for input and output moderation, and by overriding the default actions of `detect_sensitive_data` and `mask_sensitive_data` for custom detection methods.\n",
      "NVIDIA Nemo es una biblioteca de Python diseÃ±ada para ayudar en la creaciÃ³n de sistemas conversacionales seguros. Puedo proporcionar informaciÃ³n sobre cÃ³mo utilizar la biblioteca y responder preguntas sobre su tecnologÃ­a. Â¿Hay algo especÃ­fico que le gustarÃ­a saber?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d79ddb2dc8c4a9b870cb99d31f12e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can use AzureOpenAI as a feedback provider for trulens. Is there anything else you would like to know?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8457842f6d5e460b96de78ea9546b5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can use AzureOpenAI to define a trulens feedback provider.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e41521427e54f12a9f672efcbd8997d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Groundedness per statement in source:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_rails as recorder:\n",
    "    for test_prompt in test_set:\n",
    "        res = rails.generate(messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": test_prompt\n",
    "        }])\n",
    "        print(res['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improvements to our rails app are viewable both in the notebook (below) and through the TruLens dashboard launched earlier in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Language Match</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rails Application</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.761590</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.002412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rails Application - v2</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.769178</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.33</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.001913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rails Application - v3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.868349</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.002692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Answer Relevance  Language Match  Context Relevance  \\\n",
       "app_id                                                                        \n",
       "Rails Application                   0.78        0.761590                0.7   \n",
       "Rails Application - v2              0.68        0.769178                0.7   \n",
       "Rails Application - v3              0.59        0.868349                0.7   \n",
       "\n",
       "                        Groundedness  latency  total_cost  \n",
       "app_id                                                     \n",
       "Rails Application               0.28      5.4    0.002412  \n",
       "Rails Application - v2          0.33      5.4    0.001913  \n",
       "Rails Application - v3          0.49      3.8    0.002692  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
