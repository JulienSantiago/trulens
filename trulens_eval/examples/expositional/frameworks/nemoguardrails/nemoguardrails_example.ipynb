{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall -y trulens_eval\n",
    "# pip install git+https://github.com/truera/trulens@piotrm/azure_bugfixes#subdirectory=trulens_eval\n",
    "\n",
    "# trulens_eval notebook dev\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "base = Path().cwd()\n",
    "while not (base / \"trulens_eval\").exists():\n",
    "    base = base.parent\n",
    "\n",
    "print(base)\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(base))\n",
    "\n",
    "# Uncomment for more debugging printouts.\n",
    "\"\"\"\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\"\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\",\n",
    "    \"HUGGINGFACE_API_KEY\"\n",
    ")\n",
    "\n",
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "tru.run_dashboard(_dev=base, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.yaml\n",
    "# Adapted from nemoguardrails/examples/bots/abc/config.yml\n",
    "instructions:\n",
    "  - type: general\n",
    "    content: |\n",
    "      Below is a conversation between a user and a bot called the trulens Bot.\n",
    "      The bot is designed to answer questions about the trulens python library.\n",
    "      The bot is knowledgeable about the library and python.\n",
    "      If the bot does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "sample_conversation: |\n",
    "  user \"Hi there. Can you help me with some questions I have about trulens?\"\n",
    "    express greeting and ask for assistance\n",
    "  bot express greeting and confirm and offer assistance\n",
    "    \"Hi there! I'm here to help answer any questions you may have about the trulens. What would you like to know?\"\n",
    "  user \"What integrations does trulens support?\"\n",
    "    ask question about integrations\n",
    "  bot respond to question about integrations\n",
    "    \"The trulens library provides integration with langchain, llama_index, and nemo guardrails apps.Please refer to the documentation for more information.\"\n",
    "\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-3.5-turbo-instruct\n",
    "\n",
    "rails:\n",
    "#  input:\n",
    "#    flows:\n",
    "#      - self check input\n",
    "\n",
    "#  output:\n",
    "#    flows:\n",
    "#      - self check output\n",
    "\n",
    "  dialog:\n",
    "    single_call:\n",
    "      enabled: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.base import BaseLanguageModel\n",
    "\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "from nemoguardrails.actions.llm.generation import LLMGenerationActions\n",
    "\n",
    "config = RailsConfig.from_path(\".\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails.kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "from nemoguardrails.actions.actions import ActionResult, action\n",
    "\n",
    "from trulens_eval import OpenAI, Huggingface, Feedback\n",
    "hugs = Huggingface()\n",
    "\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rails)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance)\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "feedbacks = dict()\n",
    "feedbacks['language_match'] = Feedback(hugs.language_match)\n",
    "feedbacks['answer_relevance'] = f_qa_relevance\n",
    "feedbacks['groundedness'] = f_groundedness\n",
    "feedbacks['context_relevance'] = f_context_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@action(name=\"feedback\")\n",
    "async def feedback(\n",
    "    events: Optional[List[Dict]] = None, \n",
    "    context: Optional[dict] = None,\n",
    "    llm: Optional[BaseLanguageModel] = None,\n",
    "    config: Optional[RailsConfig] = None,\n",
    "    function: Optional[str] = None,\n",
    "    selectors: Optional[Dict[str, Lens]] = None\n",
    "):\n",
    "    \"\"\"Run the specified feedback function from trulens_eval.\n",
    "\n",
    "    Args:\n",
    "        context (Optional[dict]): The context for the execution of the action.\n",
    "        Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        ActionResult: An action result containing the result of the feedback.\n",
    "\n",
    "    Note:\n",
    "        ...\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        result = await run_feedback(context=my_context)\n",
    "        print(result.result)  # Score of the feedback function (between 0.0 and 1.0)\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "    feedback_function = feedbacks.get(function)\n",
    "    if feedback_function is None:\n",
    "        raise ValueError(f\"Invalid feedback function: {function}\")\n",
    "\n",
    "    if selectors is None:\n",
    "        raise ValueError(f\"Need selectors for feedback function: {feedback_function}\")\n",
    "    \n",
    "    selectors = {argname: Lens.of_string(arglens) for argname, arglens in selectors.items()}\n",
    "\n",
    "    feedback_function = feedback_function.on(**selectors)\n",
    "\n",
    "    source_data = dict(\n",
    "        action=dict(events=events, context=context, llm=llm, config=config)\n",
    "    )\n",
    "\n",
    "    context_updates = {}\n",
    "    \n",
    "    try:\n",
    "        result = feedback_function.run(source_data=source_data)\n",
    "    except Exception as e:\n",
    "        context_updates[\"result\"] = 1.0\n",
    "\n",
    "        return ActionResult(\n",
    "            return_value=context_updates[\"result\"],\n",
    "            context_updates=context_updates,\n",
    "        )\n",
    "\n",
    "    if result.result is None:\n",
    "        context_updates[\"result\"] = 1.0\n",
    "    else:\n",
    "        context_updates[\"result\"] = result.result\n",
    "\n",
    "    print(f\"{feedback_function.name} = {result.result}\")\n",
    "\n",
    "    return ActionResult(\n",
    "        return_value=context_updates[\"result\"],\n",
    "        context_updates=context_updates,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails.register_action(feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await rails.generate_async(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What does the company handbook say about pasta?\"\n",
    "}])\n",
    "    \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models.base import BaseLanguageModel\n",
    "\n",
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "from nemoguardrails.actions.llm.generation import LLMGenerationActions\n",
    "\n",
    "config = RailsConfig.from_path(\".\")\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rails.kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.feedback import RAG_triad, Feedback\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval.schema import Select\n",
    "from trulens_eval.tru_rails import RailsActionSelect, TruRails\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "\n",
    "context = App.select_context(rails)\n",
    "question = Select.RecordInput\n",
    "answer = Select.RecordOutput\n",
    "\n",
    "triad = RAG_triad(\n",
    "    provider=openai, question=question, answer=answer, context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_rails = TruRails(rails, feedbacks=triad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_rails.print_instrumented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rails as recorder:\n",
    "    response = await rails.generate_async(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Which frameworks does trulens support?\"\n",
    "}])\n",
    "    \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = recorder.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
