{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed3e8c10",
   "metadata": {},
   "source": [
    "# Evaluating Summarization with TruLens\n",
    "\n",
    "In this notebook, we will evaluate a summarization application based on [DialogSum dataset](https://github.com/cylnlp/dialogsum) using a broad set of available metrics from TruLens. These metrics break down into three categories.\n",
    "\n",
    "1. Ground truth agreement: For these set of metrics, we will measure how similar the generated summary is to some human-created ground truth. We will use for different measures: BERT score, BLEU, ROUGE and a measure where an LLM is prompted to produce a similarity score.\n",
    "2. Groundedness: Estimate if the generated summary can be traced back to parts of the original transcript both with LLM and NLI methods.\n",
    "3. Comprehensivenss: Estimate if the generated summary contains all of the key points from the source text.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/expositional/use_cases/summarization_eval.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cc6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-'\n",
    "os.environ['HUGGINGFACE_API_KEY'] = \"hf_...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "602ed89a",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "Let's first install the packages that this notebook depends on. Uncomment these linse to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install trulens_eval bert_score evaluate absl-py rouge-score pandas tenacity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f443aac",
   "metadata": {},
   "source": [
    "### Download and load data\n",
    "Now we will download a portion of the DialogSum dataset from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6769a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8133c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-14 17:11:32--  https://raw.githubusercontent.com/cylnlp/dialogsum/main/DialogSum_Data/dialogsum.dev.jsonl\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 471830 (461K) [text/plain]\n",
      "Saving to: ‘dialogsum.dev.jsonl’\n",
      "\n",
      "dialogsum.dev.jsonl 100%[===================>] 460.77K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-05-14 17:11:32 (15.7 MB/s) - ‘dialogsum.dev.jsonl’ saved [471830/471830]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O dialogsum.dev.jsonl https://raw.githubusercontent.com/cylnlp/dialogsum/main/DialogSum_Data/dialogsum.dev.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f0829ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_dev = 'dialogsum.dev.jsonl'\n",
    "dev_df = pd.read_json(path_or_buf=file_path_dev, lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7e7714b",
   "metadata": {},
   "source": [
    "Let's preview the data to make sure that the data was properly loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad85d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_0</td>\n",
       "      <td>#Person1#: Hello, how are you doing today?\\n#P...</td>\n",
       "      <td>#Person2# has trouble breathing. The doctor as...</td>\n",
       "      <td>see a doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_1</td>\n",
       "      <td>#Person1#: Hey Jimmy. Let's go workout later t...</td>\n",
       "      <td>#Person1# invites Jimmy to go workout and pers...</td>\n",
       "      <td>do exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_2</td>\n",
       "      <td>#Person1#: I need to stop eating such unhealth...</td>\n",
       "      <td>#Person1# plans to stop eating unhealthy foods...</td>\n",
       "      <td>healthy foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_3</td>\n",
       "      <td>#Person1#: Do you believe in UFOs?\\n#Person2#:...</td>\n",
       "      <td>#Person2# believes in UFOs and can see them in...</td>\n",
       "      <td>UFOs and aliens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_4</td>\n",
       "      <td>#Person1#: Did you go to school today?\\n#Perso...</td>\n",
       "      <td>#Person1# didn't go to school today. #Person2#...</td>\n",
       "      <td>go to school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dev_5</td>\n",
       "      <td>#Person1#: Honey, I think you should quit smok...</td>\n",
       "      <td>#Person1# asks #Person2# to quit smoking for h...</td>\n",
       "      <td>quit smoking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dev_6</td>\n",
       "      <td>#Person1#: Excuse me, Mr. White? I just need y...</td>\n",
       "      <td>Sherry reminds Mr. White to sign.</td>\n",
       "      <td>workplace conversation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dev_7</td>\n",
       "      <td>#Person1#: Hey, Karen. Look like you got some ...</td>\n",
       "      <td>#Person1# asks Karen where Karen stayed and ho...</td>\n",
       "      <td>holidays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dev_8</td>\n",
       "      <td>#Person1#: How do you usually spend your leisu...</td>\n",
       "      <td>#Person1# asks about #Person2#'s hobbies. #Per...</td>\n",
       "      <td>hobby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dev_9</td>\n",
       "      <td>#Person1#: have you ever seen Bill Gate's home...</td>\n",
       "      <td>#Person1# and #Person2# talk about Bill Gate's...</td>\n",
       "      <td>dream home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fname                                           dialogue  \\\n",
       "0  dev_0  #Person1#: Hello, how are you doing today?\\n#P...   \n",
       "1  dev_1  #Person1#: Hey Jimmy. Let's go workout later t...   \n",
       "2  dev_2  #Person1#: I need to stop eating such unhealth...   \n",
       "3  dev_3  #Person1#: Do you believe in UFOs?\\n#Person2#:...   \n",
       "4  dev_4  #Person1#: Did you go to school today?\\n#Perso...   \n",
       "5  dev_5  #Person1#: Honey, I think you should quit smok...   \n",
       "6  dev_6  #Person1#: Excuse me, Mr. White? I just need y...   \n",
       "7  dev_7  #Person1#: Hey, Karen. Look like you got some ...   \n",
       "8  dev_8  #Person1#: How do you usually spend your leisu...   \n",
       "9  dev_9  #Person1#: have you ever seen Bill Gate's home...   \n",
       "\n",
       "                                             summary                   topic  \n",
       "0  #Person2# has trouble breathing. The doctor as...            see a doctor  \n",
       "1  #Person1# invites Jimmy to go workout and pers...             do exercise  \n",
       "2  #Person1# plans to stop eating unhealthy foods...           healthy foods  \n",
       "3  #Person2# believes in UFOs and can see them in...         UFOs and aliens  \n",
       "4  #Person1# didn't go to school today. #Person2#...            go to school  \n",
       "5  #Person1# asks #Person2# to quit smoking for h...            quit smoking  \n",
       "6                  Sherry reminds Mr. White to sign.  workplace conversation  \n",
       "7  #Person1# asks Karen where Karen stayed and ho...                holidays  \n",
       "8  #Person1# asks about #Person2#'s hobbies. #Per...                   hobby  \n",
       "9  #Person1# and #Person2# talk about Bill Gate's...              dream home  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "716d57bc",
   "metadata": {},
   "source": [
    "## Create a simple summarization app and instrument it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62ffb3d7",
   "metadata": {},
   "source": [
    "We will create a simple summarization app based on the OpenAI ChatGPT model and instrument it for use with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2472f205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gn03249822/opt/miniconda3/envs/trulens/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.tru_custom_app import instrument\n",
    "from trulens_eval.tru_custom_app import TruCustomApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc60cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "class DialogSummaryApp:\n",
    "    \n",
    "    @instrument\n",
    "    def summarize(self, dialog):\n",
    "        client = openai.OpenAI()\n",
    "        summary = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"Summarize the given dialog into 1-2 sentences based on the following criteria: \n",
    "                     1. Convey only the most salient information; \n",
    "                     2. Be brief; \n",
    "                     3. Preserve important named entities within the conversation; \n",
    "                     4. Be written from an observer perspective; \n",
    "                     5. Be written in formal language. \"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": dialog}\n",
    "                ]\n",
    "            ).choices[0].message.content\n",
    "        return summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a81c191",
   "metadata": {},
   "source": [
    "## Initialize Database and view dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba28354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "# If you have a database you can connect to, use a URL. For example:\n",
    "# tru = Tru(database_url=\"postgresql://hostname/database?user=username&password=password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.start_dashboard(force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad02e597",
   "metadata": {},
   "source": [
    "## Write feedback functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56247d16",
   "metadata": {},
   "source": [
    "We will now create the feedback functions that will evaluate the app. Remember that the criteria we were evaluating against were:\n",
    "1. Ground truth agreement: For these set of metrics, we will measure how similar the generated summary is to some human-created ground truth. We will use for different measures: BERT score, BLEU, ROUGE and a measure where an LLM is prompted to produce a similarity score.\n",
    "2. Groundedness: For this measure, we will estimate if the generated summary can be traced back to parts of the original transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ee39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Feedback, feedback\n",
    "from trulens_eval.feedback import GroundTruthAgreement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4db1975",
   "metadata": {},
   "source": [
    "We select the golden dataset based on dataset we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2168ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_set = dev_df[['dialogue', 'summary']].rename(columns={'dialogue': 'query', 'summary': 'response'}).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI, Huggingface\n",
    "from trulens_eval import Select\n",
    "\n",
    "provider = OpenAI()\n",
    "\n",
    "ground_truth_collection = GroundTruthAgreement(golden_set, provider=provider)\n",
    "f_groundtruth = Feedback(ground_truth_collection.agreement_measure, name = \"Similarity (LLM)\").on_input_output()\n",
    "f_bert_score = Feedback(ground_truth_collection.bert_score).on_input_output()\n",
    "f_bleu = Feedback(ground_truth_collection.bleu).on_input_output()\n",
    "f_rouge = Feedback(ground_truth_collection.rouge).on_input_output()\n",
    "# Groundedness between each context chunk and the response.\n",
    "grounded_llm = feedback.Groundedness(groundedness_provider=provider)\n",
    "grounded_nli = feedback.Groundedness(groundedness_provider=Huggingface())\n",
    "f_groundedness_llm = (\n",
    "    Feedback(grounded_llm.groundedness_measure_with_cot_reasons, name = \"Groundedness - LLM Judge\")\n",
    "    .on(Select.RecordInput)\n",
    "    .on(Select.RecordOutput)\n",
    "    .aggregate(grounded_llm.grounded_statements_aggregator)\n",
    ")\n",
    "f_groundedness_nli = (\n",
    "    Feedback(grounded_nli.groundedness_measure_with_nli, name = \"Groundedness - NLI Judge\")\n",
    "    .on(Select.RecordInput)\n",
    "    .on(Select.RecordOutput)\n",
    "    .aggregate(grounded_nli.grounded_statements_aggregator)\n",
    ")\n",
    "f_comprehensiveness = (Feedback(provider.comprehensiveness_with_cot_reasons,\n",
    "                            name = \"Comprehensiveness\")\n",
    "                            .on(Select.RecordInput)\n",
    "                            .on(Select.RecordOutput))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.comprehensiveness_with_cot_reasons(\"the white house is white. obama is the president\", \"the white house is white. obama is the president\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c13f57a9",
   "metadata": {},
   "source": [
    "## Create the app and wrap it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed0c5432",
   "metadata": {},
   "source": [
    "Now we are ready to wrap our summarization app with TruLens as a `TruCustomApp`. Now each time it will be called, TruLens will log inputs, outputs and any instrumented intermediate steps and evaluate them ith the feedback functions we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = DialogSummaryApp()\n",
    "print(app.summarize(dev_df.dialogue[498]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruCustomApp(app, app_id='Summarize_v1',\n",
    "                  feedbacks = [f_groundtruth,\n",
    "                                f_groundedness_llm,\n",
    "                                f_groundedness_nli,\n",
    "                                f_comprehensiveness,\n",
    "                                f_bert_score,\n",
    "                                f_bleu,\n",
    "                                f_rouge])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2a63099",
   "metadata": {},
   "source": [
    "We can test a single run of the App as so. This should show up on the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_recorder:\n",
    "    app.summarize(dialog=dev_df.dialogue[498])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dd0f0c5",
   "metadata": {},
   "source": [
    "We'll make a lot of queries in a short amount of time, so we need tenacity to make sure that most of our requests eventually go through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4274c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def run_with_backoff(doc):\n",
    "    return ta.with_record(app.summarize, dialog=doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175df188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in golden_set:\n",
    "    llm_response = run_with_backoff(pair[\"query\"])\n",
    "    print(llm_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ae8b4b3",
   "metadata": {},
   "source": [
    "And that's it! This might take a few minutes to run, at the end of it, you can explore the dashboard to see how well your app does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
