{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruBot in Dashboard\n",
    "\n",
    "This notebook adds trubot to the dashboard so it can be queried there. See also `appui_example.ipynb` that creates the same but for interacting with the app inside a jupyter notebook.\n",
    "\n",
    "# This work is ongoing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "\n",
    "# Imports from langchain to build app:\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "import numpy as np\n",
    "\n",
    "# Imports main tools:\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval import feedback\n",
    "from trulens_eval import FeedbackMode\n",
    "from trulens_eval import Select\n",
    "from trulens_eval import TP\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.utils.langchain import WithFeedbackFilterDocuments\n",
    "\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "# Tru object manages the database of apps, records, and feedbacks; and the\n",
    "# dashboard to display these.\n",
    "tru = Tru()\n",
    "\n",
    "# Start the dasshboard. If you running from github repo, you will need to adjust\n",
    "# the path the dashboard streamlit app starts in by providing the _dev argument.\n",
    "tru.start_dashboard(\n",
    "    force = True,\n",
    "    _dev=Path().cwd().parent.parent.resolve()\n",
    ")\n",
    "\n",
    "# If needed, you can reset the trulens_eval dashboard database by running the\n",
    "# below line:\n",
    "\n",
    "# tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "app_id = \"TruBot\"\n",
    "\n",
    "# Embedding for vector db.\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-ada-002')  # 1536 dims\n",
    "\n",
    "# Local pinecone alternative. Requires precomputed 'hnswlib_truera' folder.\n",
    "from langchain.vectorstores import DocArrayHnswSearch\n",
    "\n",
    "def get_doc_search():\n",
    "    # We need to create this object in the thread in which it is used so we\n",
    "    # wrap it in this function for later usage.\n",
    "\n",
    "    docsearch = DocArrayHnswSearch.from_params(\n",
    "        embedding=embedding,\n",
    "        work_dir='hnswlib_trubot',\n",
    "        n_dim=1536,\n",
    "        max_elements=1024\n",
    "    )\n",
    "\n",
    "    return docsearch\n",
    "\n",
    "# LLM for completing prompts, and other tasks.\n",
    "llm = OpenAI(temperature=0, max_tokens=256)\n",
    "\n",
    "# Construct feedback functions.\n",
    "\n",
    "# API endpoints for models used in feedback functions:\n",
    "# hugs = feedback.Huggingface()\n",
    "openai = feedback.OpenAI()\n",
    "\n",
    "# Language match between question/answer.\n",
    "# f_lang_match = Feedback(hugs.language_match).on_input_output()\n",
    "# By default this will evaluate feedback on main app input and main app output.\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# By default this will evaluate feedback on main app input and main app output.\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_qs_relevance = feedback.Feedback(openai.qs_relevance).on_input().on(\n",
    "    Select.Record.app.combine_docs_chain._call.args.inputs.input_documents[:].page_content\n",
    ").aggregate(np.min)\n",
    "# First feedback argument is set to main app input, and the second is taken from\n",
    "# the context sources as passed to an internal `combine_docs_chain._call`.\n",
    "\n",
    "all_feedbacks = [\n",
    "    #f_lang_match, \n",
    "    #f_qa_relevance, f_qs_relevance\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v1_new_conversation(feedback_mode=FeedbackMode.WITH_APP):\n",
    "    \"\"\"\n",
    "    Create a langchain app for a new conversation with a question-answering bot.\n",
    "\n",
    "    Feedback_mode controls when feedback is evaluated:\n",
    "\n",
    "    - FeedbackMode.WITH_APP -- app will wait until feedback is evaluated before\n",
    "      returning from calls.\n",
    "\n",
    "    - FeedbackMode.WITH_APP_THREAD -- app will return from calls and evaluate\n",
    "      feedback in a new thread.\n",
    "\n",
    "    - FeedbackMode.DEFERRED -- app will return and a separate runner thread (see\n",
    "      usage later in this notebook) will evaluate feedback.\n",
    "    \"\"\"\n",
    "\n",
    "    # Blank conversation memory.\n",
    "    memory = ConversationSummaryBufferMemory(\n",
    "        max_token_limit=650,\n",
    "        llm=llm,\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key='answer'\n",
    "    )\n",
    "\n",
    "    docsearch = get_doc_search()\n",
    "\n",
    "    # Context retriever.\n",
    "    retriever = docsearch.as_retriever()\n",
    "\n",
    "    # Conversational app puts it all together.\n",
    "    app = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        memory=memory,\n",
    "        get_chat_history=lambda a: a,\n",
    "        max_tokens_limit=4096\n",
    "    )\n",
    "\n",
    "    # Trulens instrumentation.\n",
    "    tc = Tru().Chain(\n",
    "        app_id=f\"{app_id}/v1\",\n",
    "        chain=app,\n",
    "        feedbacks=all_feedbacks,\n",
    "        feedback_mode=feedback_mode, \n",
    "    )\n",
    "\n",
    "    return tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
