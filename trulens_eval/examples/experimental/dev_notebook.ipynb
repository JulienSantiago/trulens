{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Notebook\n",
    "\n",
    "This notebook loads the version of trulens_eval from the enclosing repo folder. You can use this to debug or devlop trulens_eval features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall -y trulens_eval\n",
    "# pip install git+https://github.com/truera/trulens@piotrm/azure_bugfixes#subdirectory=trulens_eval\n",
    "\n",
    "# trulens_eval notebook dev\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "base = Path().cwd()\n",
    "while not (base / \"trulens_eval\").exists():\n",
    "    base = base.parent\n",
    "\n",
    "print(base)\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(base))\n",
    "\n",
    "# Uncomment for more debugging printouts.\n",
    "\"\"\"\n",
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\"\"\"\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\",\n",
    "    \"HUGGINGFACE_API_KEY\"\n",
    ")\n",
    "\n",
    "# from trulens_eval import Tru\n",
    "# tru = Tru()\n",
    "# tru.reset_database()\n",
    "# tru.run_dashboard(_dev=base, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.v2.feedback import Template, Insensitivity\n",
    "\n",
    "t = Template.from_template(\"hello there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.tru_llama import TruLlama\n",
    "\n",
    "check_keys(\"OPENAI_API_KEY\", \"HUGGINGFACE_API_KEY\")\n",
    "import os\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "if not os.path.exists(\"data/paul_graham_essay.txt\"):\n",
    "    os.system(\n",
    "        'wget https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt -P data/'\n",
    "    )\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# This test does not run correctly if async is used, i.e. not using\n",
    "# `sync` to convert to sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider.hugs import Dummy\n",
    "from trulens_eval import Select\n",
    "from trulens_eval.feedback.feedback import Feedback\n",
    "\n",
    "f = Feedback(Dummy().language_match).on(Select.RecordCalls._retriever.retrieve.rets[42])\n",
    "\n",
    "tru_query_engine_recorder = TruLlama(query_engine, feedbacks=[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from typing import Tuple\n",
    "from trulens_eval.utils.text import make_retab\n",
    "\n",
    "fimp = Dummy().language_match\n",
    "\n",
    "invert_template = \"\"\"\n",
    "You are a fuzzing tool. Your job is to provide inputs to a function that will\n",
    "achieve a desired output. You are given a description of the function. Some\n",
    "inputs may be fixed, others are to be determined by you.\n",
    "\n",
    "BEGIN FUNCTION DESCRIPTION\n",
    "{imp_doc}\n",
    "END FUNCTION DESCRIPTION\n",
    "\n",
    "BEGIN TARGET OUTPUT\n",
    "{target}\n",
    "END TARGET OUTPUT\n",
    "\n",
    "BEGIN FIXED INPUTS\n",
    "{fixed_inputs}\n",
    "END FIXED INPUTS\n",
    "\"\"\"\n",
    "\n",
    "def invert_feedback(imp, target, **kwargs):\n",
    "    \"\"\"Try to fill in input values to feedback function `imp` to achieve output\n",
    "    value `target`. Any `kwargs` provided fix `imp` arguments to the given\n",
    "    values.\n",
    "    \"\"\"\n",
    "\n",
    "    doc = imp.__doc__\n",
    "\n",
    "    filled_template = invert_template.format(\n",
    "        imp_doc=doc,\n",
    "        target=target,\n",
    "        fixed_inputs=\"\\n\".join(\n",
    "            f\"{k}={v}\" for k, v in kwargs.items()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return filled_template\n",
    "\n",
    "#BEGIN FUNCTION DOCSTRING\n",
    "#{imp_doc}\n",
    "#END FUNCTION DOCSTRING\n",
    "\n",
    "doc_template = \"\"\"\n",
    "You are a python method summarization tool. Your job is to summarize the\n",
    "purpose, implementation, arguments, and returns of a given method based on its\n",
    "signature and source code.\n",
    "\n",
    "BEGIN FUNCTION SIGNATURE\n",
    "{sig}\n",
    "END FUNCTION SIGNATURE\n",
    "\n",
    "BEGIN FUNCTION SOURCE\n",
    "{src}\n",
    "END FUNCTION SOURCE\n",
    "\n",
    "Summarize the purpose of the method without saying how it is implemented or what\n",
    "tools are used to implement it.\n",
    "PURPOSE: <overall method purpose>\n",
    "\n",
    "Summarize how the method is implemented:\n",
    "IMPLEMENTATION: <how the method achieves its purpose>\n",
    "\n",
    "Summarize each of these arguments in this form, one per line:\n",
    "{args_templates}\n",
    "\n",
    "Summarize the function's return value. List its type, overall interpretation,\n",
    "and an interpretation extremal values it could achieve.\n",
    "{rets_templates}\n",
    "\"\"\"\n",
    "\n",
    "arg_template = \"\"\"ARGUMENT({name}: {type}): <argument_description>\"\"\"\n",
    "\n",
    "ret_template = \"\"\"\n",
    "RETURN({type}): <return1_description>\n",
    "RETURNVALUE(<return1_value1>): <interpretation for this return value>\n",
    "RETURNVALUE(<return1_value2>): <interpretation for this return value>\n",
    "\"\"\"\n",
    "\n",
    "def doc_feedback(imp):\n",
    "    \"\"\"Try to fill in input values to feedback function `imp` to achieve output\n",
    "    value `target`. Any `kwargs` provided fix `imp` arguments to the given\n",
    "    values.\n",
    "    \"\"\"\n",
    "\n",
    "    doc = imp.__doc__\n",
    "    sig = inspect.signature(imp)\n",
    "\n",
    "    rt = make_retab(\"  \")\n",
    "\n",
    "    arg_templates = \"\\n\".join(\n",
    "        arg_template.format(name=arg.name, type=arg.annotation.__name__)\n",
    "        for arg in sig.parameters.values() if arg.name != \"self\"\n",
    "    )\n",
    "\n",
    "    ret_annot = sig.return_annotation\n",
    "\n",
    "    if hasattr(ret_annot, \"__args__\"):\n",
    "        ret_types = [ret_annot.__args__[0]]\n",
    "    else:\n",
    "        ret_types = [ret_annot]\n",
    "\n",
    "    rets_templates = \"\\n\".join(\n",
    "        ret_template.format(type=ret_type.__name__)\n",
    "        for ret_type in ret_types\n",
    "    )\n",
    "    \n",
    "    filled_template = doc_template.format(\n",
    "        imp_doc=rt(doc),\n",
    "        sig=rt(imp.__name__ + str(sig)),\n",
    "        src=rt(inspect.getsource(fimp)),\n",
    "        args_templates=arg_templates,\n",
    "        rets_templates=rets_templates\n",
    "    )\n",
    "\n",
    "    return filled_template\n",
    "\n",
    "\n",
    "# invert_feedback(fimp, 1.0, text1=\"How are you?\")\n",
    "prompt = doc_feedback(Dummy().toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "c = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = c.completions.create#(model=\"gpt-3.5-turbo\", prompt=prompt)\n",
    "# help(c.chat.completions.create)\n",
    "\n",
    "d = Dummy()\n",
    "\n",
    "for fimp in [d.language_match, d.positive_sentiment, d.toxic, d.pii_detection, d.hallucination_evaluator]:\n",
    "    print(fimp.__name__)\n",
    "    prompt = doc_feedback(fimp)\n",
    "    res = c.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"system\", \"content\": prompt}], temperature=0.0)\n",
    "    print(res.choices[0].message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.utils.asynchro import sync\n",
    "\n",
    "llm_response_async, record_async = sync(tru_query_engine_recorder.awith_record,\n",
    "    query_engine.aquery, \"What did the author do growing up?\"\n",
    ")\n",
    "record_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "#with tru_query_engine_recorder as recording:\n",
    "llm_response_async, record = await tru_query_engine_recorder.awith_record(query_engine.aquery, \"What did the author do growing up?\")\n",
    "\n",
    "#record_async = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "with tru_query_engine_recorder as recording:\n",
    "    llm_response_async = query_engine.aquery(\"What did the author do growing up?\")\n",
    "\n",
    "#record_async = recording.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.base_query_engine import BaseQueryEngine\n",
    "isinstance(query_engine, BaseQueryEngine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "tru_query_engine_recorder = TruLlama(query_engine)\n",
    "with tru_query_engine_recorder as recording:\n",
    "    llm_response_sync = query_engine.query(\n",
    "        \"What did the author do growing up?\"\n",
    "    )\n",
    "record_sync = recording.get()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
