{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit App UI Example\n",
    "\n",
    "This notebook demonstrates an app interface that runs alongside the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")\n",
    "\n",
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "tru.start_dashboard(\n",
    "    force = True,\n",
    "    _dev=Path().cwd().parent.parent.resolve()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App loader\n",
    "\n",
    "To be able to create a new session or \"conversation\", we need to be able to\n",
    "reset the langchain app to its initial state. For this purpose, we require the\n",
    "callable that produces a new chain that is configured for the start of the\n",
    "conversation. Things like memory or other stateful aspects of the chain should\n",
    "be at their initial values. Because of this, we need to construct it fully\n",
    "inside the required callable. As another requirement of serialization, all of\n",
    "the relevant imports that this function needs need to be included in its\n",
    "definition locally instead of as global imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_langchain_app():\n",
    "    # All relevant imports must be inside this function.\n",
    "\n",
    "    from langchain.llms import OpenAI\n",
    "    from langchain.chains import ConversationChain\n",
    "    from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "    llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "    # Conversation memory.\n",
    "    memory = ConversationSummaryBufferMemory(\n",
    "        k=4,\n",
    "        max_token_limit=64,\n",
    "        llm=llm,\n",
    "    )\n",
    "\n",
    "    # Conversational app puts it all together.\n",
    "    app = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    return app \n",
    "\n",
    "app1 = load_langchain_app()\n",
    "\n",
    "tru_app1 = tru.Chain(\n",
    "    app1,\n",
    "    app_id='langchain_app',\n",
    "    initial_app_loader=load_langchain_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama_index example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llamaindex_app():\n",
    "    from llama_index import VectorStoreIndex, SimpleWebPageReader\n",
    "\n",
    "    documents = SimpleWebPageReader(\n",
    "        html_to_text=True\n",
    "    ).load_data([\"http://paulgraham.com/worked.html\"])\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "    query_engine = index.as_query_engine()\n",
    "\n",
    "    return query_engine\n",
    "\n",
    "app2 = load_llamaindex_app()\n",
    "tru_app2 = tru.Llama(\n",
    "    app2,\n",
    "    app_id=\"llamaindex_app\",\n",
    "    initial_app_loader=load_llamaindex_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "\n",
    "You can get a list of apps that include the `initial_app_loader` with the following utility method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.schema import AppDefinition\n",
    "\n",
    "for app_json in AppDefinition.get_loadable_apps():\n",
    "    print(app_json['app_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
