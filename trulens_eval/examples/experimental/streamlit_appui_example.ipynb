{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit App UI Example\n",
    "\n",
    "This notebook demonstrates an app interface that runs alongside the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# If running from github repo, can use this:\n",
    "sys.path.append(str(Path().cwd().parent.parent.resolve()))\n",
    "\n",
    "from trulens_eval.keys import check_keys\n",
    "\n",
    "check_keys(\n",
    "    \"OPENAI_API_KEY\"\n",
    ")\n",
    "\n",
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "tru.start_dashboard(\n",
    "    force = True,\n",
    "    _dev=Path().cwd().parent.parent.resolve()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App loader\n",
    "\n",
    "To be able to create a new session or \"conversation\", we need to be able to\n",
    "reset the langchain app to its initial state. For this purpose, we require the\n",
    "callable that produces a new chain that is configured for the start of the\n",
    "conversation. Things like memory or other stateful aspects of the chain should\n",
    "be at their initial values. Because of this, we need to construct it fully\n",
    "inside the required callable.\n",
    "\n",
    "**NOTE**: As another requirement of serialization, all of the relevant imports\n",
    "that this function needs need to be included in its definition locally instead\n",
    "of as global imports.\n",
    "\n",
    "**WARNING**: This function will be naively serialized using `dill` and will fail a\n",
    "size check if this serialization is too big. Because of this, you cannot rely on\n",
    "large global objects in the function's closure and need to load them as part of\n",
    "the execution of the function instead.\n",
    "\n",
    "**WARNING**: This function needs to return a new instance of the app independent\n",
    "of any others produced earlier. That is, you cannot take an existing or\n",
    "pre-loaded app, clear its memory, and return it. As part of the dashboard,\n",
    "multiple instances of an app need to operate at the same time without\n",
    "interference in their states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_langchain_app():\n",
    "    # All relevant imports must be inside this function.\n",
    "\n",
    "    from langchain.llms import OpenAI\n",
    "    from langchain.chains import ConversationChain\n",
    "    from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "    llm = OpenAI(temperature=0.9, max_tokens=128)\n",
    "\n",
    "    # Conversation memory.\n",
    "    memory = ConversationSummaryBufferMemory(\n",
    "        k=4,\n",
    "        max_token_limit=64,\n",
    "        llm=llm,\n",
    "    )\n",
    "\n",
    "    # Conversational app puts it all together.\n",
    "    app = ConversationChain(\n",
    "        llm=llm,\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    return app \n",
    "\n",
    "app1 = load_langchain_app()\n",
    "\n",
    "tru_app1 = tru.Chain(\n",
    "    app1,\n",
    "    app_id='langchain_app',\n",
    "    initial_app_loader=load_langchain_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama_index example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llamaindex_app():\n",
    "    from llama_index import VectorStoreIndex, SimpleWebPageReader\n",
    "\n",
    "    # Note that this is not an efficient way to create the app as it downloads\n",
    "    # the web page every time the app needs to create a new session. Saving the\n",
    "    # site locally would be a better idea.\n",
    "    documents = SimpleWebPageReader(\n",
    "        html_to_text=True\n",
    "    ).load_data([\"http://paulgraham.com/worked.html\"])\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "    query_engine = index.as_query_engine()\n",
    "\n",
    "    return query_engine\n",
    "\n",
    "app2 = load_llamaindex_app()\n",
    "tru_app2 = tru.Llama(\n",
    "    app2,\n",
    "    app_id=\"llamaindex_app\",\n",
    "    initial_app_loader=load_llamaindex_app\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "\n",
    "You can get a list of apps that include the `initial_app_loader` with the following utility method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.schema import AppDefinition\n",
    "\n",
    "for app_json in AppDefinition.get_loadable_apps():\n",
    "    print(app_json['app_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
