{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "In this quickstart you will create a simple Llama Index App and learn how to log it and get feedback on an LLM response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies\n",
    "Let's install some of the dependencies for this notebook if we don't have them already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install trulens-eval\n",
    "#!pip install llama_index==0.6.31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add API keys\n",
    "For this quickstart, you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "#os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from LlamaIndex and TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No .env found in /home/shayak/code/trulens/trulens_eval/examples/frameworks/llama_index or its parents. You may need to specify secret keys in another manner.\n"
     ]
    }
   ],
   "source": [
    "# Imports main tools:\n",
    "from trulens_eval import TruLlama, Feedback, Tru, feedback\n",
    "tru = Tru()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple LLM Application\n",
    "\n",
    "This example uses LlamaIndex which internally uses an OpenAI LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLama Index starter example from: https://gpt-index.readthedocs.io/en/latest/getting_started/starter_example.html\n",
    "# In order to run this, download into data/ Paul Graham's Essay 'What I Worked On' from https://github.com/jerryjliu/llama_index/blob/main/examples/paul_graham_essay/data/paul_graham_essay.txt \n",
    "\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send your first request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = query_engine.query(\"What did the author do growing up?\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feedback Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In language_match, input text1 will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In language_match, input text2 will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
      "✅ In relevance, input prompt will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In relevance, input response will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
      "✅ In qs_relevance, input question will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In qs_relevance, input statement will be set to *.__record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize Huggingface-based feedback function collection class:\n",
    "hugs = feedback.Huggingface()\n",
    "openai = feedback.OpenAI()\n",
    "\n",
    "# Define a language match feedback function using HuggingFace.\n",
    "f_lang_match = Feedback(hugs.language_match).on_input_output()\n",
    "# By default this will check language match on the main app input and main app\n",
    "# output.\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_qs_relevance = Feedback(openai.qs_relevance).on_input().on(\n",
    "    TruLlama.select_source_nodes().node.text\n",
    ").aggregate(np.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_set = [\n",
    "    {\"query\": \"What was the author's undergraduate major?\", \"response\": \"He didn't choose a major, and customized his courses.\"},\n",
    "    {\"query\": \"What company did the author start in 1995?\", \"response\": \"Viaweb, to make software for building online stores.\"},\n",
    "    {\"query\": \"Where did the author move in 1998 after selling Viaweb?\", \"response\": \"California, after Yahoo acquired Viaweb.\"},\n",
    "    {\"query\": \"What did the author do after leaving Yahoo in 1999?\", \"response\": \"He focused on painting and tried to improve his art skills.\"},\n",
    "    {\"query\": \"What program did the author start with Jessica Livingston in 2005?\", \"response\": \"Y Combinator, to provide seed funding for startups.\"}\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In agreement_measure, input prompt will be set to *.__record__.main_input or `Select.RecordInput` .\n",
      "✅ In agreement_measure, input response will be set to *.__record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "f_groundtruth = Feedback(openai.GroundTruthAgreement(golden_set).agreement_measure).on_input_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument chain for logging with TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ app LlamaIndex_App1 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_893bf600540de189bca2d4c2d84731a4 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_661a9eeb1b5c8d40fac0332aa866b848 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_a7ff177399bdf82c0027aa7f2e4e3783 -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_a8adb28134a95ba7ff167af8b9832562 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "tru_query_engine = TruLlama(query_engine,\n",
    "    app_id='LlamaIndex_App1',\n",
    "    feedbacks=[f_lang_match, f_qa_relevance, f_qs_relevance, f_groundtruth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The author does not mention where they were born in the context information provided.\n",
      "✅ record record_hash_0f9ef2099fa55956ff64769faf30e761 from LlamaIndex_App1 -> default.sqlite\n",
      "✅ feedback feedback_result_hash_94525ec12e1b0c1057c0d82e65c185e4 on record_hash_0f9ef2099fa55956ff64769faf30e761 -> default.sqlite\n",
      "✅ feedback feedback_result_hash_45fd96bdd2aeea3b3b39bca1f1396f47 on record_hash_0f9ef2099fa55956ff64769faf30e761 -> default.sqlite\n",
      "✅ feedback feedback_result_hash_9c20340b5e4edaf800510b8e34ffbf52 on record_hash_0f9ef2099fa55956ff64769faf30e761 -> default.sqlite\n",
      "✅ feedback feedback_result_hash_b9b6b806cbdb76edf799290703d6757f on record_hash_0f9ef2099fa55956ff64769faf30e761 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "# Instrumented query engine can operate like the original:\n",
    "llm_response = tru_query_engine.query(\"Where was the author born?\")\n",
    "\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The author's undergraduate major was philosophy.\n",
      "✅ record record_hash_2e38582d67e232f205b4ecf9dba54e4e from LlamaIndex_App1 -> default.sqlite\n",
      "He didn't choose a major, and customized his courses.\n",
      "5\n",
      "0.5\n",
      "✅ feedback feedback_result_hash_f2d147ac97195592cb45d97ab882c5b0 on record_hash_2e38582d67e232f205b4ecf9dba54e4e -> default.sqlite\n",
      "✅ feedback feedback_result_hash_60c97d19a95badfe4a2d326f27b39d9f on record_hash_2e38582d67e232f205b4ecf9dba54e4e -> default.sqlite\n",
      "✅ feedback feedback_result_hash_07d226d3787225e7f62bb830ea491f06 on record_hash_2e38582d67e232f205b4ecf9dba54e4e -> default.sqlite\n",
      "✅ feedback feedback_result_hash_b6b8feddf8957703433645d102350e68 on record_hash_2e38582d67e232f205b4ecf9dba54e4e -> default.sqlite\n",
      "\n",
      "The author started the company Viaweb in 1995.\n",
      "✅ record record_hash_3ab4955890239c83eab9a222c596fadb from LlamaIndex_App1 -> default.sqlite\n",
      "Viaweb, to make software for building online stores.\n",
      "10\n",
      "1.0\n",
      "✅ feedback feedback_result_hash_34abbeb1367a0f5cd77aa1823f6e507b on record_hash_3ab4955890239c83eab9a222c596fadb -> default.sqlite\n",
      "✅ feedback feedback_result_hash_306aad5ee9754c9d1a802c454a4ff647 on record_hash_3ab4955890239c83eab9a222c596fadb -> default.sqlite\n",
      "✅ feedback feedback_result_hash_69fa817ebaac053c3795fb7bb9fa8683 on record_hash_3ab4955890239c83eab9a222c596fadb -> default.sqlite\n",
      "✅ feedback feedback_result_hash_ccc63e868cd98a6a1569e89bec20e9a3 on record_hash_3ab4955890239c83eab9a222c596fadb -> default.sqlite\n",
      "\n",
      "The author moved to Cambridge, Massachusetts in 1998 after selling Viaweb.\n",
      "✅ record record_hash_5b04aba3709ad6c3bee669fd533a945a from LlamaIndex_App1 -> default.sqlite\n",
      "California, after Yahoo acquired Viaweb.\n",
      "2\n",
      "0.2\n",
      "✅ feedback feedback_result_hash_44abad4c2f302bb8e7aea76766617bb2 on record_hash_5b04aba3709ad6c3bee669fd533a945a -> default.sqlite\n",
      "✅ feedback feedback_result_hash_ac844e2186af8caba25255d1a6ef1b75 on record_hash_5b04aba3709ad6c3bee669fd533a945a -> default.sqlite\n",
      "✅ feedback feedback_result_hash_bd5295642b4561b55fccd6a0695a5f32 on record_hash_5b04aba3709ad6c3bee669fd533a945a -> default.sqlite\n",
      "✅ feedback feedback_result_hash_0a2dfeecf835d319ac59226da3dadbd5 on record_hash_5b04aba3709ad6c3bee669fd533a945a -> default.sqlite\n",
      "\n",
      "After leaving Yahoo in 1999, the author returned to New York and resumed his old life, except now he was rich. He tried to paint, but found he lacked energy and ambition. He looked for an apartment to buy, and experimented with a new kind of still life painting. He also wrote essays and published them online, and worked on spam filters. He also had dinners for a group of friends every Thursday night, which taught him how to cook for groups. He also bought a building in Cambridge to use as an office.\n",
      "✅ record record_hash_d6c53f7432fa4040e1f136b90331ff0a from LlamaIndex_App1 -> default.sqlite\n",
      "He focused on painting and tried to improve his art skills.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 44.49275207519531} (44.49275207519531) second(s).\n",
      "Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 44.49275207519531} (44.49275207519531) second(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.4\n",
      "\n",
      "The program the author started with Jessica Livingston in 2005 was Y Combinator, an angel investment firm.\n",
      "✅ record record_hash_22620c71a0f55f534f509d10e357fcdb from LlamaIndex_App1 -> default.sqlite\n",
      "Y Combinator, to provide seed funding for startups.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 44.49275207519531} (44.49275207519531) second(s).\n",
      "Waiting for {'error': 'Model papluca/xlm-roberta-base-language-detection is currently loading', 'estimated_time': 44.49275207519531} (44.49275207519531) second(s).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Run and evaluate on groundtruth questions\n",
    "for pair in golden_set:\n",
    "    llm_response = tru_query_engine.query(pair['query'])\n",
    "    print(llm_response)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore in a Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaderboard\n",
    "\n",
    "Understand how your LLM application is performing at a glance. Once you've set up logging and evaluation in your application, you can view key performance statistics including cost and average feedback value across all of your LLM apps using the chain leaderboard. As you iterate new versions of your LLM application, you can compare their performance across all of the different quality metrics you've set up.\n",
    "\n",
    "Note: Average feedback values are returned and displayed in a range from 0 (worst) to 1 (best).\n",
    "\n",
    "![Chain Leaderboard](https://www.trulens.org/Assets/image/Leaderboard.png)\n",
    "\n",
    "To dive deeper on a particular chain, click \"Select Chain\".\n",
    "\n",
    "### Understand chain performance with Evaluations\n",
    " \n",
    "To learn more about the performance of a particular chain or LLM model, we can select it to view its evaluations at the record level. LLM quality is assessed through the use of feedback functions. Feedback functions are extensible methods for determining the quality of LLM responses and can be applied to any downstream LLM task. Out of the box we provide a number of feedback functions for assessing model agreement, sentiment, relevance and more.\n",
    "\n",
    "The evaluations tab provides record-level metadata and feedback on the quality of your LLM application.\n",
    "\n",
    "![Evaluations](https://www.trulens.org/Assets/image/Leaderboard.png)\n",
    "\n",
    "### Deep dive into full chain metadata\n",
    "\n",
    "Click on a record to dive deep into all of the details of your chain stack and underlying LLM, captured by tru_chain.\n",
    "\n",
    "![Explore a Chain](https://www.trulens.org/Assets/image/Chain_Explore.png)\n",
    "\n",
    "If you prefer the raw format, you can quickly get it using the \"Display full chain json\" or \"Display full record json\" buttons at the bottom of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or view results directly in your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tru.get_records_and_feedback(app_ids=[])[0] # pass an empty list of app_ids to get all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5737f6101ac92451320b0e41890107145710b89f85909f3780d702e7818f973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
