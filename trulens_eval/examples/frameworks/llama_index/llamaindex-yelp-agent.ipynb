{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama-Index Agents + Custom Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI Agent\n",
    "from llama_index.agent import OpenAIAgent\n",
    "import openai\n",
    "openai.api_key = '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and initialize our tool spec\n",
    "from llama_hub.tools.yelp.base import YelpToolSpec\n",
    "from llama_index.tools.tool_spec.load_and_search.base import LoadAndSearchToolSpec\n",
    "\n",
    "tool_spec = YelpToolSpec(api_key='...', client_id='...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_standalone(prompt):\n",
    "    return openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a question and answer bot, and you answer concisely.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are numerous good restaurants in Toronto, some popular ones include Canoe, Richmond Station, Alo Restaurant, Pai, and Bar Isabel.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_standalone(\"what are good restaurants in toronto?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent with our tools\n",
    "tools = tool_spec.to_tool_list()\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [\n",
    "        *LoadAndSearchToolSpec.from_defaults(tools[0]).to_tool_list(),\n",
    "        *LoadAndSearchToolSpec.from_defaults(tools[1]).to_tool_list()\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: business_search with args: {\n",
      "  \"location\": \"Toronto\",\n",
      "  \"term\": \"restaurants\"\n",
      "}\n",
      "Got output: Content loaded! You can now search the information using read_business_search\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: read_business_search with args: {\n",
      "  \"query\": \"good restaurants in Toronto\"\n",
      "}\n",
      "Got output: \n",
      "Based on the context information, some good restaurants in Toronto include Ristorante Sotto Sotto, The Oxley, KINKA IZAKAYA ORIGINAL, and Dirty Food Eatery.\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='Some good restaurants in Toronto include Ristorante Sotto Sotto, The Oxley, KINKA IZAKAYA ORIGINAL, and Dirty Food Eatery.', sources=[ToolOutput(content='Content loaded! You can now search the information using read_business_search', tool_name='business_search', raw_input={'args': (), 'kwargs': {'location': 'Toronto', 'term': 'restaurants'}}, raw_output='Content loaded! You can now search the information using read_business_search'), ToolOutput(content='\\nBased on the context information, some good restaurants in Toronto include Ristorante Sotto Sotto, The Oxley, KINKA IZAKAYA ORIGINAL, and Dirty Food Eatery.', tool_name='read_business_search', raw_input={'args': (), 'kwargs': {'query': 'good restaurants in Toronto'}}, raw_output='\\nBased on the context information, some good restaurants in Toronto include Ristorante Sotto Sotto, The Oxley, KINKA IZAKAYA ORIGINAL, and Dirty Food Eatery.')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"what are good restaurants in toronto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In definitive, input response will be set to *.__record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback, OpenAI, Tru, TruBasicApp, TruLlama\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "class OpenAI_custom(OpenAI):\n",
    "    def definitive(self, response: str) -> float:\n",
    "\n",
    "        return float(openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Your job is to rate how definitive the following text is on a scale of 1 to 10. Respond with the number only.\"},\n",
    "            {\"role\": \"user\", \"content\": response}\n",
    "        ]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]) / 10\n",
    "\n",
    "custom = OpenAI_custom()\n",
    "definitive = Feedback(custom.definitive).on_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715ff879218e42d5aa44775e9cd7fa27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.4.23:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ app OpenAIChatCompletion -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_491763e5a520c2e026ec536169856e41 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "standalone_app = TruBasicApp(llm_standalone, app_id=\"OpenAIChatCompletion\", feedbacks=[definitive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ app YelpAgent -> default.sqlite\n",
      "✅ feedback def. feedback_definition_hash_491763e5a520c2e026ec536169856e41 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "yelp_app = TruLlama(agent,\n",
    "    app_id='YelpAgent',\n",
    "    feedbacks=[definitive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"The best poutine in Montreal is subjective and can vary based on personal taste. However, popular places for poutine include La Banquise, Patati Patata, and Ma'am Bolduc.\",\n",
       " Record(record_id='record_hash_c03260cb30bc7242438197370d0bf658', app_id='OpenAIChatCompletion', cost=Cost(n_requests=1, n_successful_requests=1, n_classes=0, n_tokens=76, n_prompt_tokens=36, n_completion_tokens=40, cost=0.000134), perf=Perf(start_time=datetime.datetime(2023, 7, 20, 12, 46, 37, 792108), end_time=datetime.datetime(2023, 7, 20, 12, 46, 39, 963763)), ts=datetime.datetime(2023, 7, 20, 12, 46, 39, 963812), tags='-', main_input='Where is the best poutine in montreal?', main_output=\"The best poutine in Montreal is subjective and can vary based on personal taste. However, popular places for poutine include La Banquise, Patati Patata, and Ma'am Bolduc.\", main_error='None', calls=[RecordAppCall(stack=(RecordAppCallMethod(path=JSONPath().app, method=Method(obj=Obj(cls=trulens_eval.tru_basic_app.TruWrapperApp, id=5431210640), name='<lambda>')),), args={'args': ['Where is the best poutine in montreal?']}, rets=\"The best poutine in Montreal is subjective and can vary based on personal taste. However, popular places for poutine include La Banquise, Patati Patata, and Ma'am Bolduc.\", error=None, perf=Perf(start_time=datetime.datetime(2023, 7, 20, 12, 46, 37, 824896), end_time=datetime.datetime(2023, 7, 20, 12, 46, 39, 963464)), pid=17074, tid=164138)]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ record record_hash_c03260cb30bc7242438197370d0bf658 from OpenAIChatCompletion -> default.sqlite"
     ]
    }
   ],
   "source": [
    "standalone_app.call_with_record(\"Where is the best poutine in montreal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ feedback feedback_result_hash_be9508abac93e976a34d1358d7c906bd on record_hash_c03260cb30bc7242438197370d0bf658 -> default.sqlite\n",
      "=== Calling Function ===\n",
      "Calling function: business_search with args: {\n",
      "  \"location\": \"Montreal\",\n",
      "  \"term\": \"poutine\"\n",
      "}\n",
      "Got output: Content loaded! You can now search the information using read_business_search\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: read_business_search with args: {\n",
      "  \"query\": \"best poutine in Montreal\"\n",
      "}\n",
      "Got output: \n",
      "Based on the context information provided, the best poutine in Montreal appears to be Poutineville, which has a 4.5 star rating and 40 reviews.\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='The best poutine in Montreal is at Poutineville. It has a rating of 4.5 stars and 40 reviews.', source_nodes=[], metadata=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ record record_hash_685f548cc22064d405eead007b13f764 from YelpAgent -> default.sqlite\n",
      "✅ feedback feedback_result_hash_c68db2c051ed4e681eab575108367432 on record_hash_685f548cc22064d405eead007b13f764 -> default.sqlite\n"
     ]
    }
   ],
   "source": [
    "yelp_app.query(\"Where is the best poutine in montreal?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('pinecone_example')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68aa9cfa264c12f07062d08edcac5e8f20877de71ce1cea15160e4e8ae95e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
