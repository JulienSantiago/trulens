{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X6-q-gTUaZU7"
      },
      "source": [
        "# Advanced Evaluation with TruEra\n",
        "\n",
        "Using TruLens, we can create fine-grained evaluations for complex queries.\n",
        "\n",
        "Using the sub-question sentence-window engine from previous notebooks, let's create a custom evaluation framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTSzmVFIaffU",
        "outputId": "0fe81f4b-80c5-4811-fba3-49c45cac2d90"
      },
      "outputs": [],
      "source": [
        "#!pip install trulens-eval==0.12.0 llama-index==0.8.29post1 sentence-transformers transformers pypdf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SnwSnBkSaZU8"
      },
      "source": [
        "## Query Engine Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IBfdyn3MaZU9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"...\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh43sV1eaZU9",
        "outputId": "f356b401-d4c2-4496-da7c-9fb9fe4c9b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 20.7M  100 20.7M    0     0  27.5M      0 --:--:-- --:--:-- --:--:-- 27.7M\n"
          ]
        }
      ],
      "source": [
        "!curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wMvq1q8yaZU-"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"./IPCC_AR6_WGII_Chapter03.pdf\"]\n",
        ").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sY8Oui4taZU-"
      },
      "outputs": [],
      "source": [
        "# Merge into a single large document rather than one document per-page\n",
        "from llama_index import Document\n",
        "\n",
        "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MkbaDRJCaZU_"
      },
      "outputs": [],
      "source": [
        "from llama_index import ServiceContext\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index.node_parser import SentenceWindowNodeParser\n",
        "\n",
        "# create the sentence window node parser w/ default settings\n",
        "node_parser = SentenceWindowNodeParser.from_defaults(\n",
        "    window_size=3,\n",
        "    window_metadata_key=\"window\",\n",
        "    original_text_metadata_key=\"original_text\",\n",
        ")\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
        "sentence_context = ServiceContext.from_defaults(\n",
        "    llm=llm,\n",
        "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
        "    node_parser=node_parser,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JQPRoF21aZU_"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "\n",
        "sentence_index = VectorStoreIndex.from_documents(\n",
        "    [document], service_context=sentence_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RAERQ_BeaZU_"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.postprocessor import (\n",
        "    MetadataReplacementPostProcessor,\n",
        "    SentenceTransformerRerank,\n",
        ")\n",
        "\n",
        "sentence_window_engine = sentence_index.as_query_engine(\n",
        "    similarity_top_k=6,\n",
        "    # the target key defaults to `window` to match the node_parser's default\n",
        "    node_postprocessors=[\n",
        "        MetadataReplacementPostProcessor(target_metadata_key=\"window\"),\n",
        "        SentenceTransformerRerank(top_n=2, model=\"BAAI/bge-reranker-base\"),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PCsOz-3ZaZVB"
      },
      "outputs": [],
      "source": [
        "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "sentence_sub_engine = SubQuestionQueryEngine.from_defaults(\n",
        "  [QueryEngineTool(\n",
        "    query_engine=sentence_window_engine,\n",
        "    metadata=ToolMetadata(name=\"climate_report\", description=\"Climate Report on Oceans.\")\n",
        "  )],\n",
        "  service_context=sentence_context,\n",
        "  verbose=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5KqV-IbQaZVB"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gZyCMs25aZVB"
      },
      "source": [
        "## Custom Eval Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN3k1zsXaZVB",
        "outputId": "41797123-8028-4165-d700-6b4a1a60f308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted 130 rows.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from trulens_eval import Feedback, OpenAI, Tru, TruLlama, feedback, Select, FeedbackMode\n",
        "\n",
        "tru = Tru()\n",
        "\n",
        "tru.reset_database()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXJBD4gfaZVC",
        "outputId": "b4ebd2f9-1768-47be-d0eb-8963f7076ecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ In helpfulness, input text will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
            "✅ In Answer Relevance, input prompt will be set to *.__record__.main_input or `Select.RecordInput` .\n",
            "✅ In Answer Relevance, input response will be set to *.__record__.main_output or `Select.RecordOutput` .\n",
            "✅ In Subquestion Context Relevance, input question will be set to *.__record__.main_input or `Select.RecordInput` .\n",
            "✅ In Subquestion Context Relevance, input statement will be set to *.__record__.calls[0].rets.source_nodes[:].node.text .\n",
            "✅ In Context Relevance, input question will be set to *.__record__.main_input or `Select.RecordInput` .\n",
            "✅ In Context Relevance, input statement will be set to *.__record__.calls[0].args.prompt_args.context_str .\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize Huggingface-based feedback function collection class:\n",
        "openai = feedback.OpenAI()\n",
        "\n",
        "# Helpfulness\n",
        "f_helpfulness = feedback = Feedback(openai.helpfulness).on_output() \n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "# The context is located in a different place for the sub questions so we need to define that feedback separately\n",
        "f_qs_relevance_subquestions = (\n",
        "    Feedback(openai.qs_relevance)\n",
        "    .on_input()\n",
        "    .on(Select.Record.calls[0].rets.source_nodes[:].node.text)\n",
        "    .aggregate(np.mean))\n",
        "\n",
        "f_qs_relevance = (\n",
        "    Feedback(openai.qs_relevance)\n",
        "    .on_input()\n",
        "    .on(Select.Record.calls[0].args.prompt_args.context_str)\n",
        "    .aggregate(np.mean))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KUDHInR-aZVC"
      },
      "outputs": [],
      "source": [
        "# We'll use the recorder in deferred mode so we can log all of the subquestions before starting eval.\n",
        "# This approach will give us smoother handling for the evals + more consistent logging at high volume.\n",
        "# In addition, for our two different qs relevance definitions, deferred mode can just take the one that evaluates.\n",
        "tru_recorder = TruLlama(\n",
        "    sentence_sub_engine,\n",
        "    app_id=\"CustomEvalTest\",\n",
        "    feedbacks=[f_qa_relevance, f_qs_relevance, f_qs_relevance_subquestions, f_helpfulness],\n",
        "    feedback_mode=FeedbackMode.DEFERRED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dsA3ziw1aZVD"
      },
      "outputs": [],
      "source": [
        "# subset of questions from the \"Advanced RAG\" notebook\n",
        "questions = [\n",
        "  \"Based on the provided text, discuss the impact of human activities on the natural carbon dynamics of estuaries, shelf seas, and other intertidal and shallow-water habitats. Provide examples from the text to support your answer.\",\n",
        "  \"Analyze the combined effects of exploitation and multi-decadal climate fluctuations on global fisheries yields. How do these factors make it difficult to assess the impacts of global climate change on fisheries yields? Use specific examples from the text to support your analysis.\",\n",
        "  \"Based on the study by Gutiérrez-Rodríguez, A.G., et al., 2018, what potential benefits do seaweeds have in the field of medicine, specifically in relation to cancer treatment?\",\n",
        "  \"According to the research conducted by Haasnoot, M., et al., 2020, how does the uncertainty in Antarctic mass-loss impact the coastal adaptation strategy of the Netherlands?\",\n",
        "  \"Based on the context, explain how the decline in warm water coral reefs is projected to impact the services they provide to society, particularly in terms of coastal protection.\",\n",
        "  \"Tell me something about the intricacies of tying a tie.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01_P6TxaaZVD",
        "outputId": "4f03da5b-34a3-4d41-ee78-9c09bc97368e"
      },
      "outputs": [],
      "source": [
        "for question in questions:\n",
        "  with tru_recorder as recording:\n",
        "    sentence_sub_engine.query(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Thread(Thread-77 (runloop), started 14354604032)>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_1588b559040ebb69e2d6366147df0fb9\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_1588b559040ebb69e2d6366147df0fb9\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_1588b559040ebb69e2d6366147df0fb9\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_1588b559040ebb69e2d6366147df0fb9\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_9e0615cec3fbceb8a75651022098dbae\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_9e0615cec3fbceb8a75651022098dbae\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_9e0615cec3fbceb8a75651022098dbae\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_9e0615cec3fbceb8a75651022098dbae\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_e6c332ae687e38b9cdb19adc71d1fa55\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_e6c332ae687e38b9cdb19adc71d1fa55\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_e6c332ae687e38b9cdb19adc71d1fa55\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_e6c332ae687e38b9cdb19adc71d1fa55\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_680f9e3d9e7ce3a84726464243027be6\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_680f9e3d9e7ce3a84726464243027be6\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_680f9e3d9e7ce3a84726464243027be6\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_680f9e3d9e7ce3a84726464243027be6\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_208b86f415378a2e35c08659ca82bd4f\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_208b86f415378a2e35c08659ca82bd4f\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_208b86f415378a2e35c08659ca82bd4f\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_208b86f415378a2e35c08659ca82bd4f\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_74e73e092811a410c59e978c304c3cec\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_74e73e092811a410c59e978c304c3cec\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_74e73e092811a410c59e978c304c3cec\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_74e73e092811a410c59e978c304c3cec\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_8d4c5f8888cc13b9e8815f4a1ae8b388\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_8d4c5f8888cc13b9e8815f4a1ae8b388\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_8d4c5f8888cc13b9e8815f4a1ae8b388\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_8d4c5f8888cc13b9e8815f4a1ae8b388\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_cd1c12dc8da40a16a8d07474e894b1a5\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_cd1c12dc8da40a16a8d07474e894b1a5\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_cd1c12dc8da40a16a8d07474e894b1a5\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_cd1c12dc8da40a16a8d07474e894b1a5\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_335fe3d02fcfa8629d3cea110246ac0e\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_335fe3d02fcfa8629d3cea110246ac0e\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_335fe3d02fcfa8629d3cea110246ac0e\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_8288714160f8372faa4d356ca8f80025\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_335fe3d02fcfa8629d3cea110246ac0e\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_8288714160f8372faa4d356ca8f80025\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_8288714160f8372faa4d356ca8f80025\n",
            "Task queue full. Finishing existing tasks.\n",
            "Could not locate *.calls[0].rets.source_nodes[:].node.text in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_8288714160f8372faa4d356ca8f80025\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_f15e458a6214789a5eb73f837998afa9\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_f15e458a6214789a5eb73f837998afa9\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_f15e458a6214789a5eb73f837998afa9\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_f15e458a6214789a5eb73f837998afa9\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_e78ae3273b35bb7d7fbc2bf626423e29\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_e78ae3273b35bb7d7fbc2bf626423e29\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_e78ae3273b35bb7d7fbc2bf626423e29\n",
            "Could not locate *.calls[0].rets.source_nodes[:].node.text in app/record.\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_e78ae3273b35bb7d7fbc2bf626423e29\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_4d99847247ac3acfc6e5d869a85eb0de\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_4d99847247ac3acfc6e5d869a85eb0de\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_4d99847247ac3acfc6e5d869a85eb0de\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_4d99847247ac3acfc6e5d869a85eb0de\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_fb56c3500b6e6dde034353b3672d631b\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_fb56c3500b6e6dde034353b3672d631b\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_fb56c3500b6e6dde034353b3672d631b\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_fb56c3500b6e6dde034353b3672d631b\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_38fb3e1c0642d1142dec3d693816b7f2\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_38fb3e1c0642d1142dec3d693816b7f2\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_38fb3e1c0642d1142dec3d693816b7f2\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_38fb3e1c0642d1142dec3d693816b7f2\n",
            "Could not locate *.calls[0].rets.source_nodes[:].node.text in app/record.\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_0b69b2f5df00269919e71363b4a31192\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_0b69b2f5df00269919e71363b4a31192\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_0b69b2f5df00269919e71363b4a31192\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_0b69b2f5df00269919e71363b4a31192\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_6b2f74163f99b3bf86e41b09673bb9b5\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_6b2f74163f99b3bf86e41b09673bb9b5\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_6b2f74163f99b3bf86e41b09673bb9b5\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_6b2f74163f99b3bf86e41b09673bb9b5\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_9e1b39be40585ae90c734df212b74154\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_9e1b39be40585ae90c734df212b74154\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_9e1b39be40585ae90c734df212b74154\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_9e1b39be40585ae90c734df212b74154\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_38bc869d6550f984cf6bee6f90c89f98\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_38bc869d6550f984cf6bee6f90c89f98\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_38bc869d6550f984cf6bee6f90c89f98\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_38bc869d6550f984cf6bee6f90c89f98\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_21cb6a604978a4c4a49e28f80ce5e53f\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_21cb6a604978a4c4a49e28f80ce5e53f\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_21cb6a604978a4c4a49e28f80ce5e53f\n",
            "Could not locate *.calls[0].rets.source_nodes[:].node.text in app/record.\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_21cb6a604978a4c4a49e28f80ce5e53f\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_dada482eca320f7fdde75b8da8d303a2\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_dada482eca320f7fdde75b8da8d303a2\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_dada482eca320f7fdde75b8da8d303a2\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_dada482eca320f7fdde75b8da8d303a2\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_1c2ca20aabdabae21f3f465b6f101fa3\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_1c2ca20aabdabae21f3f465b6f101fa3\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_1c2ca20aabdabae21f3f465b6f101fa3\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_1c2ca20aabdabae21f3f465b6f101fa3\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_98b19c1ad34510b253d7d5979bfb6387\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_98b19c1ad34510b253d7d5979bfb6387\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_98b19c1ad34510b253d7d5979bfb6387\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_646a013d69b4b0a63185f7f79b2d60ff\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_98b19c1ad34510b253d7d5979bfb6387\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_646a013d69b4b0a63185f7f79b2d60ff\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_646a013d69b4b0a63185f7f79b2d60ff\n",
            "Could not locate *.calls[0].rets.source_nodes[:].node.text in app/record.\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_646a013d69b4b0a63185f7f79b2d60ff\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_45a6f181da8613d13575264abf258259\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_45a6f181da8613d13575264abf258259\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_45a6f181da8613d13575264abf258259\n",
            "⚡ Feedback task starting: helpfulness for app CustomEvalTest, record record_hash_45a6f181da8613d13575264abf258259\n",
            "⚡ Feedback task starting: relevance for app CustomEvalTest, record record_hash_5096185bd5f17a03618ba2ce74e3ca54\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_5096185bd5f17a03618ba2ce74e3ca54\n",
            "⚡ Feedback task starting: qs_relevance for app CustomEvalTest, record record_hash_5096185bd5f17a03618ba2ce74e3ca54\n",
            "Task queue full. Finishing existing tasks.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n",
            "Could not locate *.calls[0].args.prompt_args.context_str in app/record.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1-10 rating regex failed to match on: 'I apologize, but as an AI language model, I am unable to assess the helpfulness, insightfulness, and appropriateness of a submission.'\n",
            "1-10 rating regex failed to match on: 'I apologize for the confusion. Since there is no specific submission mentioned, I cannot provide a rating.'\n"
          ]
        }
      ],
      "source": [
        "tru.start_evaluator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Yp4_e4faZVD",
        "outputId": "d2ba9d2d-7e2a-46d2-8459-41ba3778eba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting dashboard ...\n",
            "Config file already exists. Skipping writing process.\n",
            "Credentials file already exists. Skipping writing process.\n",
            "npx: installed 22 in 3.398s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://whole-tires-travel.loca.lt\n",
            "\n",
            "  Submit this IP Address: 35.230.82.227\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# launches on http://localhost:8501/\n",
        "tru.run_dashboard()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "milvus",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
