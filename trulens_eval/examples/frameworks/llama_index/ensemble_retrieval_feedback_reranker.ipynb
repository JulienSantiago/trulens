{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf1de44-4047-46cf-a04c-dbf910d9e179",
   "metadata": {},
   "source": [
    "# Ensemble Retrieval Guide - Feedback Rerankers\n",
    "\n",
    "Oftentimes when building a RAG applications there are many retreival parameters/strategies to decide from (from chunk size to vector vs. keyword vs. hybrid search, for instance). \n",
    "\n",
    "This example builds on top of work from Llama-Index to do ensemble retrieval over different chunk sizes and also different indices by extending the rerankers to any feedback function.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/frameworks/llama_index/ensemble_retrieval_feedback_reranker.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb85536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73fead-ec2c-4346-bd08-e183c13c7e29",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d59778-4cda-47b5-8cd0-b80fee91d1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes.\n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c628448c-573c-4eeb-a7e1-707fe8cc575c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().handlers = []\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    ListIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    SimpleKeywordTableIndex,\n",
    ")\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787174ed-10ce-47d7-82fd-9ca7f891eea7",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We first show how to convert a Document into a set of Nodes, and insert into a DocumentStore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd62366b-8a24-40a7-8c47-5859851149fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try loading great gatsby\n",
    "\n",
    "from llama_index import VectorStoreIndex, SimpleWebPageReader\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"http://paulgraham.com/worked.html\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7081194a-ede7-478e-bff2-23e89e23ef16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 128\n",
      "Chunk Size: 256\n",
      "Chunk Size: 512\n",
      "Chunk Size: 1024\n"
     ]
    }
   ],
   "source": [
    "# initialize service context (set chunk size)\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "chunk_sizes = [128, 256, 512, 1024]\n",
    "service_contexts = []\n",
    "nodes_list = []\n",
    "vector_indices = []\n",
    "query_engines = []\n",
    "for chunk_size in chunk_sizes:\n",
    "    print(f\"Chunk Size: {chunk_size}\")\n",
    "    service_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\n",
    "    service_contexts.append(service_context)\n",
    "    nodes = service_context.node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "    # add chunk size to nodes to track later\n",
    "    for node in nodes:\n",
    "        node.metadata[\"chunk_size\"] = chunk_size\n",
    "        node.excluded_embed_metadata_keys = [\"chunk_size\"]\n",
    "        node.excluded_llm_metadata_keys = [\"chunk_size\"]\n",
    "\n",
    "    nodes_list.append(nodes)\n",
    "\n",
    "    # build vector index\n",
    "    vector_index = VectorStoreIndex(nodes)\n",
    "    vector_indices.append(vector_index)\n",
    "\n",
    "    # query engines\n",
    "    query_engines.append(vector_index.as_query_engine())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae867e7",
   "metadata": {},
   "source": [
    "## Set up Retrievers with each query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbca69b4-d8d5-4dcb-af33-f9ed4a91ec05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try ensemble retrieval\n",
    "\n",
    "from llama_index.tools.retriever_tool import RetrieverTool\n",
    "\n",
    "retriever_tools = []\n",
    "for chunk_size, vector_index in zip(chunk_sizes, vector_indices):\n",
    "    retriever_tool = RetrieverTool.from_defaults(\n",
    "        retriever=vector_index.as_retriever(),\n",
    "        description=f\"Retrieves relevant context from Paul Graham's essay (chunk size {chunk_size})\",\n",
    "    )\n",
    "    retriever_tools.append(retriever_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9eaa6f-8f11-4380-b3c6-79092f17def3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.selectors.pydantic_selectors import PydanticMultiSelector\n",
    "from llama_index.retrievers import RouterRetriever\n",
    "\n",
    "\n",
    "retriever = RouterRetriever(\n",
    "    selector=PydanticMultiSelector.from_defaults(llm=llm, max_outputs=4),\n",
    "    retriever_tools=retriever_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c72c61c-d4f7-4159-bb80-1989468ab61c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting retriever 0: This choice retrieves relevant context from Paul Graham's essay with a manageable chunk size, which may contain information about his journey to founding YC..\n",
      "Selecting retriever 1: This choice retrieves a larger context from the essay, which could provide more detailed information about Paul Graham's journey to founding YC..\n",
      "Selecting retriever 2: This choice retrieves an even larger context from the essay, which could provide a comprehensive understanding of Paul Graham's journey to founding YC..\n",
      "Selecting retriever 3: This choice retrieves the largest context from the essay, which could provide the most detailed and comprehensive understanding of Paul Graham's journey to founding YC..\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=23 request_id=933485d101cc05e4799998cce4dc3bcb response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=38 request_id=eb0292eea29b71e0abfdc7bb70082fb5 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=22 request_id=d842942adac6064dc1b119a3bfdcd3e5 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=5fabce86eace0c66146f52e87c4ae0a5 response_code=200\n"
     ]
    }
   ],
   "source": [
    "nodes = await retriever.aretrieve(\n",
    "    \"Describe and summarize Paul Graham's journey to founding YC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590ed8bc-83ad-4851-9ec6-bfbbdf3ff38d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "two:\n",
      "writing essays and working on YC.  \n",
      "  \n",
      "YC was different from other kinds of work I've done. Instead of deciding for\n",
      "myself what to work on, the problems came to me. Every 6 months there was a\n",
      "new batch of startups, and their problems, whatever they were, became our\n",
      "problems. It was very engaging work, because their problems were quite varied,\n",
      "and the good founders were very effective. If you were trying to learn the\n",
      "most you could about startups in the shortest possible\n",
      "128\n",
      "set of customers almost entirely from among\n",
      "their batchmates.  \n",
      "  \n",
      "I had not originally intended YC to be a full-time job. I was going to do\n",
      "three things: hack, write essays, and work on YC. As YC grew, and I grew more\n",
      "excited about it, it started to take up a lot more than a third of my\n",
      "attention. But for the first few years I was still able to work on other\n",
      "things.  \n",
      "  \n",
      "In the summer of 2006, Robert and I started working on a new version of\n",
      "256\n",
      "Now lots\n",
      "of startups get their initial set of customers almost entirely from among\n",
      "their batchmates.  \n",
      "  \n",
      "I had not originally intended YC to be a full-time job. I was going to do\n",
      "three things: hack, write essays, and work on YC. As YC grew, and I grew more\n",
      "excited about it, it started to take up a lot more than a third of my\n",
      "attention. But for the first few years I was still able to work on other\n",
      "things.  \n",
      "  \n",
      "In the summer of 2006, Robert and I started working on a new version of Arc.\n",
      "This one was reasonably fast, because it was compiled into Scheme. To test\n",
      "this new Arc, I wrote Hacker News in it. It was originally meant to be a news\n",
      "aggregator for startup founders and was called Startup News, but after a few\n",
      "months I got tired of reading about nothing but startups. Plus it wasn't\n",
      "startup founders we wanted to reach. It was future startup founders. So I\n",
      "changed the name to Hacker News and the topic to whatever\n",
      "256\n",
      "Aaron\n",
      "Swartz, who had already helped write the RSS spec and would a few years later\n",
      "become a martyr for open access, and Sam Altman, who would later become the\n",
      "second president of YC. I don't think it was entirely luck that the first\n",
      "batch was so good. You had to be pretty bold to sign up for a weird thing like\n",
      "the Summer Founders Program instead of a summer job at a legit place like\n",
      "Microsoft or Goldman Sachs.  \n",
      "  \n",
      "The deal for startups was based on a combination of the deal we did with\n",
      "Julian ($10k for 10%) and what Robert said MIT grad students got for the\n",
      "summer ($6k). We invested $6k per founder, which in the typical two-founder\n",
      "case was $12k, in return for 6%. That had to be fair, because it was twice as\n",
      "good as the deal we ourselves had taken. Plus that first summer, which was\n",
      "really hot, Jessica brought the founders free air conditioners. [16]  \n",
      "  \n",
      "Fairly quickly I realized that we had stumbled upon\n",
      "512\n",
      "and from those\n",
      "we picked 8 to fund. They were an impressive group. That first batch included\n",
      "reddit, Justin Kan and Emmett Shear, who went on to found Twitch, Aaron\n",
      "Swartz, who had already helped write the RSS spec and would a few years later\n",
      "become a martyr for open access, and Sam Altman, who would later become the\n",
      "second president of YC. I don't think it was entirely luck that the first\n",
      "batch was so good. You had to be pretty bold to sign up for a weird thing like\n",
      "the Summer Founders Program instead of a summer job at a legit place like\n",
      "Microsoft or Goldman Sachs.  \n",
      "  \n",
      "The deal for startups was based on a combination of the deal we did with\n",
      "Julian ($10k for 10%) and what Robert said MIT grad students got for the\n",
      "summer ($6k). We invested $6k per founder, which in the typical two-founder\n",
      "case was $12k, in return for 6%. That had to be fair, because it was twice as\n",
      "good as the deal we ourselves had taken. Plus that first summer, which was\n",
      "really hot, Jessica brought the founders free air conditioners. [16]  \n",
      "  \n",
      "Fairly quickly I realized that we had stumbled upon the way to scale startup\n",
      "funding. Funding startups in batches was more convenient for us, because it\n",
      "meant we could do things for a lot of startups at once, but being part of a\n",
      "batch was better for the startups too. It solved one of the biggest problems\n",
      "faced by founders: the isolation. Now you not only had colleagues, but\n",
      "colleagues who understood the problems you were facing and could tell you how\n",
      "they were solving them.  \n",
      "  \n",
      "As YC grew, we started to notice other advantages of scale. The alumni became\n",
      "a tight community, dedicated to helping one another, and especially the\n",
      "current batch, whose shoes they remembered being in. We also noticed that the\n",
      "startups were becoming one another's customers. We used to refer jokingly to\n",
      "the \"YC GDP,\" but as YC grows this becomes less and less of a joke.\n",
      "512\n",
      "to work a good deal _in_ Arc, I gradually stopped working _on_ Arc,\n",
      "partly because I didn't have time to, and partly because it was a lot less\n",
      "attractive to mess around with the language now that we had all this\n",
      "infrastructure depending on it. So now my three projects were reduced to two:\n",
      "writing essays and working on YC.  \n",
      "  \n",
      "YC was different from other kinds of work I've done. Instead of deciding for\n",
      "myself what to work on, the problems came to me. Every 6 months there was a\n",
      "new batch of startups, and their problems, whatever they were, became our\n",
      "problems. It was very engaging work, because their problems were quite varied,\n",
      "and the good founders were very effective. If you were trying to learn the\n",
      "most you could about startups in the shortest possible time, you couldn't have\n",
      "picked a better way to do it.  \n",
      "  \n",
      "There were parts of the job I didn't like. Disputes between cofounders,\n",
      "figuring out when people were lying to us, fighting with people who maltreated\n",
      "the startups, and so on. But I worked hard even at the parts I didn't like. I\n",
      "was haunted by something Kevin Hale once said about companies: \"No one works\n",
      "harder than the boss.\" He meant it both descriptively and prescriptively, and\n",
      "it was the second part that scared me. I wanted YC to be good, so if how hard\n",
      "I worked set the upper bound on how hard everyone else worked, I'd better work\n",
      "very hard.  \n",
      "  \n",
      "One day in 2010, when he was visiting California for interviews, Robert Morris\n",
      "did something astonishing: he offered me unsolicited advice. I can only\n",
      "remember him doing that once before. One day at Viaweb, when I was bent over\n",
      "double from a kidney stone, he suggested that it would be a good idea for him\n",
      "to take me to the hospital. That was what it took for Rtm to offer unsolicited\n",
      "advice. So I remember his exact words very clearly. \"You know,\" he said, \"you\n",
      "should make sure Y Combinator isn't the last cool thing you do.\"  \n",
      "  \n",
      "At the\n",
      "1024\n",
      "with bylaws and stock and all that stuff, how on earth did you\n",
      "do that? Our plan was not only to make seed investments, but to do for\n",
      "startups everything Julian had done for us.  \n",
      "  \n",
      "YC was not organized as a fund. It was cheap enough to run that we funded it\n",
      "with our own money. That went right by 99% of readers, but professional\n",
      "investors are thinking \"Wow, that means they got all the returns.\" But once\n",
      "again, this was not due to any particular insight on our part. We didn't know\n",
      "how VC firms were organized. It never occurred to us to try to raise a fund,\n",
      "and if it had, we wouldn't have known where to start. [14]  \n",
      "  \n",
      "The most distinctive thing about YC is the batch model: to fund a bunch of\n",
      "startups all at once, twice a year, and then to spend three months focusing\n",
      "intensively on trying to help them. That part we discovered by accident, not\n",
      "merely implicitly but explicitly due to our ignorance about investing. We\n",
      "needed to get experience as investors. What better way, we thought, than to\n",
      "fund a whole bunch of startups at once? We knew undergrads got temporary jobs\n",
      "at tech companies during the summer. Why not organize a summer program where\n",
      "they'd start startups instead? We wouldn't feel guilty for being in a sense\n",
      "fake investors, because they would in a similar sense be fake founders. So\n",
      "while we probably wouldn't make much money out of it, we'd at least get to\n",
      "practice being investors on them, and they for their part would probably have\n",
      "a more interesting summer than they would working at Microsoft.  \n",
      "  \n",
      "We'd use the building I owned in Cambridge as our headquarters. We'd all have\n",
      "dinner there once a week  on tuesdays, since I was already cooking for the\n",
      "thursday diners on thursdays  and after dinner we'd bring in experts on\n",
      "startups to give talks.  \n",
      "  \n",
      "We knew undergrads were deciding then about summer jobs, so in a matter of\n",
      "days we cooked up something we called the Summer Founders Program, and I\n",
      "posted an [_announcement_](summerfounder.html) on my site, inviting undergrads\n",
      "to apply. I had never imagined that writing essays would be a way to get \"deal\n",
      "flow,\" as investors call it, but it turned out to be the perfect source. [15]\n",
      "We got 225 applications for the Summer Founders Program, and we were surprised\n",
      "to find that a lot of them were from people who'd already graduated, or were\n",
      "about to that spring. Already this SFP thing was starting to feel more serious\n",
      "than we'd intended.  \n",
      "  \n",
      "We invited about 20 of the 225 groups to interview in person, and from those\n",
      "we picked 8 to fund. They were an impressive group. That first batch included\n",
      "reddit, Justin Kan and Emmett Shear, who went on to found Twitch, Aaron\n",
      "Swartz, who had already helped write the RSS spec and would a few years later\n",
      "become a martyr for open access, and Sam Altman, who would later become the\n",
      "second president of YC. I don't think it was entirely luck that the first\n",
      "batch was so good. You had to be pretty bold to sign up for a weird thing like\n",
      "the Summer Founders Program instead of a summer job at a legit place like\n",
      "Microsoft or Goldman Sachs.  \n",
      "  \n",
      "The deal for startups was based on a combination of the deal we did with\n",
      "Julian ($10k for 10%) and what Robert said MIT grad students got for the\n",
      "summer ($6k). We invested $6k per founder, which in the typical two-founder\n",
      "case was $12k, in return for 6%. That had to be fair, because it was twice as\n",
      "good as the deal we ourselves had taken. Plus that first summer, which was\n",
      "really hot, Jessica brought the founders free air conditioners. [16]  \n",
      "  \n",
      "Fairly quickly I realized that we had stumbled upon the way to scale startup\n",
      "funding. Funding startups in batches was more convenient for us, because it\n",
      "meant we could do things for a lot of startups at once, but being part of a\n",
      "batch was better for the startups too. It\n",
      "1024\n",
      "at once, but being part of a\n",
      "batch was better for the startups too. It solved one of the biggest problems\n",
      "faced by founders: the isolation. Now you not only had colleagues, but\n",
      "colleagues who understood the problems you were facing and could tell you how\n",
      "they were solving them.  \n",
      "  \n",
      "As YC grew, we started to notice other advantages of scale. The alumni became\n",
      "a tight community, dedicated to helping one another, and especially the\n",
      "current batch, whose shoes they remembered being in. We also noticed that the\n",
      "startups were becoming one another's customers. We used to refer jokingly to\n",
      "the \"YC GDP,\" but as YC grows this becomes less and less of a joke. Now lots\n",
      "of startups get their initial set of customers almost entirely from among\n",
      "their batchmates.  \n",
      "  \n",
      "I had not originally intended YC to be a full-time job. I was going to do\n",
      "three things: hack, write essays, and work on YC. As YC grew, and I grew more\n",
      "excited about it, it started to take up a lot more than a third of my\n",
      "attention. But for the first few years I was still able to work on other\n",
      "things.  \n",
      "  \n",
      "In the summer of 2006, Robert and I started working on a new version of Arc.\n",
      "This one was reasonably fast, because it was compiled into Scheme. To test\n",
      "this new Arc, I wrote Hacker News in it. It was originally meant to be a news\n",
      "aggregator for startup founders and was called Startup News, but after a few\n",
      "months I got tired of reading about nothing but startups. Plus it wasn't\n",
      "startup founders we wanted to reach. It was future startup founders. So I\n",
      "changed the name to Hacker News and the topic to whatever engaged one's\n",
      "intellectual curiosity.  \n",
      "  \n",
      "HN was no doubt good for YC, but it was also by far the biggest source of\n",
      "stress for me. If all I'd had to do was select and help founders, life would\n",
      "have been so easy. And that implies that HN was a mistake. Surely the biggest\n",
      "source of stress in one's work should at least be something close to the core\n",
      "of the work. Whereas I was like someone who was in pain while running a\n",
      "marathon not from the exertion of running, but because I had a blister from an\n",
      "ill-fitting shoe. When I was dealing with some urgent problem during YC, there\n",
      "was about a 60% chance it had to do with HN, and a 40% chance it had do with\n",
      "everything else combined. [17]  \n",
      "  \n",
      "As well as HN, I wrote all of YC's internal software in Arc. But while I\n",
      "continued to work a good deal _in_ Arc, I gradually stopped working _on_ Arc,\n",
      "partly because I didn't have time to, and partly because it was a lot less\n",
      "attractive to mess around with the language now that we had all this\n",
      "infrastructure depending on it. So now my three projects were reduced to two:\n",
      "writing essays and working on YC.  \n",
      "  \n",
      "YC was different from other kinds of work I've done. Instead of deciding for\n",
      "myself what to work on, the problems came to me. Every 6 months there was a\n",
      "new batch of startups, and their problems, whatever they were, became our\n",
      "problems. It was very engaging work, because their problems were quite varied,\n",
      "and the good founders were very effective. If you were trying to learn the\n",
      "most you could about startups in the shortest possible time, you couldn't have\n",
      "picked a better way to do it.  \n",
      "  \n",
      "There were parts of the job I didn't like. Disputes between cofounders,\n",
      "figuring out when people were lying to us, fighting with people who maltreated\n",
      "the startups, and so on. But I worked hard even at the parts I didn't like. I\n",
      "was haunted by something Kevin Hale once said about companies: \"No one works\n",
      "harder than the boss.\" He meant it both descriptively and prescriptively, and\n",
      "it was the second part that scared me. I wanted YC to be good, so if how hard\n",
      "I worked set the upper bound on how hard everyone else worked, I'd better work\n",
      "very hard.  \n",
      "  \n",
      "One day in 2010, when he was visiting California for\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node.node.metadata[\"chunk_size\"])\n",
    "    print(node.node.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa8db4",
   "metadata": {},
   "source": [
    "## Set up Reranker\n",
    "\n",
    "Here we'll subclass LLM Reranker, replacing the reranking prompt with our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f26c527-17d2-4d4e-a6ee-8ea878ef8742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import LLMRerank\n",
    "from trulens_eval.feedback_prompts import QS_RELEVANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ec8b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_select_prompt = (\"A list of documents is shown below. Each document has a number next to it along \"\n",
    "    \"with a summary of the document. A question is also provided. \\n\"\n",
    "    \"Respond with the numbers of the documents \"\n",
    "    \"you should consult to answer the question, in order of its score.\\n\"\n",
    "    \"Do not include any documents that are not relevant to the question. \\n\"\n",
    "    f\"\"\"The score definition is {QS_RELEVANCE.replace(\"{question}\",\"{query_str}\").replace(\"{statement}\",\"{context_str}\")}\\n\"\"\"\n",
    "    \"Example format: \\n\"\n",
    "    \"Document 1:\\n<summary of document 1>\\n\\n\"\n",
    "    \"...\\n\\n\"\n",
    "    \"Document 10:\\n<summary of document 10>\\n\\n\"\n",
    "    \"Question: <question>\\n\"\n",
    "    \"Answer:\\n\"\n",
    "    \"Doc: 9, Relevance: 7\\n\"\n",
    "    \"Doc: 7, Relevance: 3\\n\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional\n",
    "from llama_index.prompts.prompts import QuestionAnswerPrompt\n",
    "\n",
    "class Feedback_Rerank(LLMRerank):\n",
    "    \"\"\"LLM-based reranker with a different choice select prompt.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        choice_select_prompt: Optional[QuestionAnswerPrompt] = None,\n",
    "        choice_batch_size: int = 10,\n",
    "        format_node_batch_fn: Optional[Callable] = None,\n",
    "        parse_choice_select_answer_fn: Optional[Callable] = None,\n",
    "        service_context: Optional[ServiceContext] = None,\n",
    "        top_n: int = 10,\n",
    "    ) -> None:\n",
    "        # Create a QuestionAnswerPrompt instance from the formatted string\n",
    "        super().__init__(\n",
    "            choice_select_prompt=choice_select_prompt,\n",
    "            choice_batch_size=choice_batch_size,\n",
    "            format_node_batch_fn=format_node_batch_fn,\n",
    "            parse_choice_select_answer_fn=parse_choice_select_answer_fn,\n",
    "            service_context=service_context,\n",
    "            top_n=top_n,\n",
    "        )\n",
    "\n",
    "# Usage example\n",
    "feedback_reranker = Feedback_Rerank(choice_select_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "828589ef-d062-40dc-8a4b-245190769445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define RetrieverQueryEngine\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine(retriever, node_postprocessors=[feedback_reranker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e3c341-e66d-4950-88d5-6411699d064b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting retriever 0: This choice might provide a concise summary of Paul Graham's journey to founding YC, but it might not contain all the necessary details due to the small chunk size..\n",
      "Selecting retriever 1: This choice might provide a more detailed summary of Paul Graham's journey to founding YC, but it might still miss some important details due to the medium chunk size..\n",
      "Selecting retriever 2: This choice is likely to provide a comprehensive summary of Paul Graham's journey to founding YC due to the large chunk size..\n",
      "Selecting retriever 3: This choice is likely to provide the most detailed and comprehensive summary of Paul Graham's journey to founding YC due to the largest chunk size. However, it might also include unnecessary details..\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Describe and summarize Paul Graham's journey to founding YC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9001f509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Paul Graham's journey to founding Y Combinator began with his work in the programming language Arc. He gradually stopped working on Arc due to lack of time and lack of interest, and instead focused on writing essays and working on YC. YC was different from other kinds of work he had done, as the problems came to him and he was able to learn a lot about startups in a short amount of time. He worked hard, even at the parts he didn't like, and was motivated by the idea that his hard work would set the upper bound for how hard everyone else worked. \n",
       "\n",
       "In 2010, Robert Morris gave him unsolicited advice to make sure YC wasn't the last cool thing he did. Paul Graham then created the Summer Founders Program, which offered $6k per founder in return for 6% equity. This was twice as good as the deal he and Julian had taken, and Jessica provided free air conditioners to the founders. He quickly realized that funding startups in batches was more convenient and beneficial for both parties, and as YC grew, he noticed other advantages of scale, such as the alumni community and startups becoming one another's customers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 6c4018b2-4ab3-48b0-ad03-3f2d93ad0749<br>**Similarity:** 10.0<br>**Text:** to work a good deal _in_ Arc, I gradually stopped working _on_ Arc,\n",
       "partly because I didn't have ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3d8a614f-e0e8-4d19-b7c7-1ccc16b95768<br>**Similarity:** 8.0<br>**Text:** and from those\n",
       "we picked 8 to fund. They were an impressive group. That first batch included\n",
       "redd...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 3/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 68a3594e-d50a-4ef0-9d32-dca0565d5c7b<br>**Similarity:** 5.0<br>**Text:** Aaron\n",
       "Swartz, who had already helped write the RSS spec and would a few years later\n",
       "become a mart...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response, show_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a7a8303-be94-45c5-8bc5-13ec8c7f1694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the average precision for each chunk size based on positioning in combined ranking\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def mrr_all(metadata_values, metadata_key, source_nodes):\n",
    "    # source nodes is a ranked list\n",
    "    # go through each value, find out positioning in source_nodes\n",
    "    value_to_mrr_dict = {}\n",
    "    for metadata_value in metadata_values:\n",
    "        mrr = 0\n",
    "        for idx, source_node in enumerate(source_nodes):\n",
    "            if source_node.node.metadata[metadata_key] == metadata_value:\n",
    "                mrr = 1 / (idx + 1)\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # normalize AP, set in dict\n",
    "        value_to_mrr_dict[metadata_value] = mrr\n",
    "\n",
    "    df = pd.DataFrame(value_to_mrr_dict, index=[\"MRR\"])\n",
    "    df.style.set_caption(\"Mean Reciprocal Rank\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adebbb82-764e-4b45-933e-84bf4ad64d40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank for each Chunk Size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MRR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     128       256   512   1024\n",
       "MRR     0  0.333333   1.0     0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the Mean Reciprocal Rank for each chunk size (higher is better)\n",
    "# we can see that chunk size of 256 has the highest ranked results.\n",
    "print(\"Mean Reciprocal Rank for each Chunk Size\")\n",
    "mrr_all(chunk_sizes, \"chunk_size\", response.source_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a2f3c-55ce-4fa6-a15a-be539723a967",
   "metadata": {},
   "source": [
    "## Compare Against Baseline\n",
    "\n",
    "Compare against a baseline of chunk size 1024 (k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4d66b14-4f38-4b61-809c-f603d7e09ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine_1024 = query_engines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43f3e441-f372-4df2-ae21-71fa7968e606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_1024 = query_engine_1024.query(\n",
    "    \"Describe and summarize the journey of Paul Graham to founding YC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b161e69-da17-4e4e-b8c0-b9c846ce723f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Paul Graham founded YC in 2005 with the intention of providing seed investments to startups and helping them in the same way that Julian had helped him. He and his co-founders funded YC with their own money, and created the batch model of funding a bunch of startups all at once, twice a year, and then spending three months focusing intensively on helping them. They invited 225 applicants to interview for the Summer Founders Program, and from those they picked 8 to fund. \n",
       "\n",
       "The deal for startups was based on a combination of the deal they had taken and what MIT grad students got for the summer. They invested $6k per founder, which in the typical two-founder case was $12k, in return for 6%. YC grew quickly, and Paul noticed other advantages of scale, such as the alumni becoming a tight community, dedicated to helping one another, and the startups becoming one another's customers. \n",
       "\n",
       "Paul had not originally intended YC to be a full-time job, but it eventually took up most of his attention. In 2006, he and Robert started working on a new version of Arc, and Paul wrote Hacker News in it. Hacker News was a source of stress for Paul, but it was also good for YC. In 2010, Paul decided to make YC his full-time job."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** beb0fa9c-e983-4107-b47b-96527ee0f579<br>**Similarity:** 0.8423639909762414<br>**Text:** with bylaws and stock and all that stuff, how on earth did you\n",
       "do that? Our plan was not only to make seed investments, but to do for\n",
       "startups everything Julian had done for us.  \n",
       "  \n",
       "YC was not organized as a fund. It was cheap enough to run that we funded it\n",
       "with our own money. That went right by 99% of readers, but professional\n",
       "investors are thinking \"Wow, that means they got all the returns.\" But once\n",
       "again, this was not due to any particular insight on our part. We didn't know\n",
       "how VC firm...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 4f124164-e957-4e21-aa3e-c521b7534bdc<br>**Similarity:** 0.8359661885485107<br>**Text:** at once, but being part of a\n",
       "batch was better for the startups too. It solved one of the biggest problems\n",
       "faced by founders: the isolation. Now you not only had colleagues, but\n",
       "colleagues who understood the problems you were facing and could tell you how\n",
       "they were solving them.  \n",
       "  \n",
       "As YC grew, we started to notice other advantages of scale. The alumni became\n",
       "a tight community, dedicated to helping one another, and especially the\n",
       "current batch, whose shoes they remembered being in. We also no...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(response_1024, show_source=True, source_length=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('agents')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d153714b979d5e6d08dd8ec90712dd93bff2c9b6c1f0c118169738af3430cd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
